# Kubernetesé›†ç¾¤æ¢å¤å’Œé«˜å¯ç”¨è®¾è®¡é¡¹ç›®å®æˆ˜

## ä¸€ã€å­¦ä¹ ç›®æ ‡

K8Sé›†ç¾¤çš„æ•…éšœæ¢å¤ï¼ˆ IPåœ°å€å‘ç”Ÿå˜æ›´åï¼Œæˆ‘ä»¬è¦æ€ä¹ˆæ¢å¤ï¼Ÿéœ€è¦ç†Ÿæ‚‰k8sä¸­çš„ç›¸å…³ç»„ä»¶å’Œå„ç»„ä»¶çš„åè°ƒå·¥ä½œçš„æµç¨‹ ï¼‰
    Calico ç½‘ç»œæ’ä»¶
    LNMP ä¸šåŠ¡å¼‚å¸¸ï¼ˆä¸»è¦å˜æ›´å¯¼è‡´çš„ï¼‰ 
    MySQL å˜æ›´ç®¡ç† 
    æ•°æ®æŒä¹…åŒ–ï¼šå½“æˆ‘ä»¬çš„PODé‡å¯/ é”€æ¯é‡å»ºçš„æ—¶å€™ï¼ŒDBï¼ˆMySQL Redisï¼‰ æ•°æ®ä¸èƒ½ä¸¢
    ç°æœ‰é›†ç¾¤è´Ÿè½½æ¯”è¾ƒé«˜ï¼šéœ€è¦æ–°å¢ node èŠ‚ç‚¹
    å½“ä¸šåŠ¡æµé‡çªå¢çš„æ—¶å€™ï¼Œ æˆ‘ä»¬PODè¦èƒ½å¤Ÿæ°´å¹³æ‰©ç¼©å®¹ HPAæ§åˆ¶å™¨ æ‰©å‰¯æœ¬ï¼Ÿ å‚ç›´æ‰©ç¼©å®¹VPAï¼Ÿæ‰©cpuå’Œmem 
    MySQLé«˜å¯ç”¨éƒ¨ç½²ï¼Ÿ 
    Rediså¦‚æœè¿›è¡Œå“¨å…µ/é›†ç¾¤æ¨¡å¼çš„é«˜å¯ç”¨éƒ¨ç½²ï¼Ÿ



## äºŒã€å®æˆ˜å†…å®¹

ä»»åŠ¡1ï¼šå°†æ¯ä¸ªèŠ‚ç‚¹çš„IPåœ°å€æ›´æ”¹ä¸ºéœ€æ±‚çš„ç½‘æ®µIP

å¯èƒ½ä¼šå‡ºç°çš„å¼‚å¸¸ç°è±¡ï¼š

å¼‚å¸¸ç°è±¡1: INTERNAL-IP å­—æ®µæ˜¯ä¸å¯¹çš„ï¼Ÿ
å¼‚å¸¸ç°è±¡2: [root@master01 ~]# kubectl get nodes
Unable to connect to the server: dial tcp 10.3.201.100:6443: connect: no route to host
å¼‚å¸¸ç°è±¡3: Unable to connect to the server: tls: failed to verify certificate: x509: certificate is valid for 10.0.0.1, 10.3.201.100, not 10.3.204.100


ä»»åŠ¡2:ï¼šè§£å†³å®Œä¸Šè¿°æ‰€æœ‰å¼‚å¸¸ç°è±¡ï¼Œç„¶å kubectl get nodes -o wide å‘½ä»¤è¾“å‡ºçš„é›†ç¾¤ä¿¡æ¯æ˜¯æ­£å¸¸çš„


ä»»åŠ¡3ï¼šæ¢å¤ kube-system é‡Œ calico ç»„ä»¶

```shell
[root@master01 ~]# kubectl get pods -n kube-system | grep calico
calico-kube-controllers-558d465845-4blqv   0/1     CrashLoopBackOff   8 (2m5s ago)      148d
calico-node-4t2zw                          0/1     Init:1/3           0                 8s
calico-node-sggl6                          0/1     Init:1/3           0                 8s
calico-node-tfvhv                          0/1     Init:1/3           0                 8s
calico-typha-5b56944f9b-gnrpr              1/1     Running            1 (18m ago)       148d
```


ä»»åŠ¡4: LNMPä¸šåŠ¡å¼‚å¸¸æ¢å¤

- å°†`/root/resources/01.nginx.yaml,02.phpfpm.yaml,03.mysql.yaml`ç­‰æ–‡ä»¶ä¸­NFSåœ°å€æŒ‡å‘æœ¬é›†ç¾¤master01
- ä¸º`nginx.yaml,phpfpm.yaml`ç­‰æ–‡ä»¶æ·»åŠ å¥åº·æ£€æŸ¥æœºåˆ¶
- æ£€æŸ¥`nginx php-fpm mysql`æœåŠ¡
- é€šè¿‡`bbs.iproute.cn`è®¿é—®æ­£å¸¸


ä»»åŠ¡5: MySQLå˜æ›´ç®¡ç†

- ä¿®æ”¹æ–°å¯†ç ä¸º:`123456`
- è®¿é—® `bbs.iproute.cn` æ­£å¸¸


ä»»åŠ¡6: RedisæŒä¹…åŒ–ç®¡ç†

- é…ç½®æ–‡ä»¶é€šè¿‡ConfigmapæŒ‚è½½è‡³ `/usr/local/etc/redis/redis.conf`
- æ•°æ®ç›®å½•é€šè¿‡NFSæŒ‚è½½è‡³ `/data`
- æµ‹è¯•éªŒè¯


ä»»åŠ¡7ï¼šæ–°å¢å·¥ä½œèŠ‚ç‚¹ï¼Œæ·»åŠ 1å°node


æ‰©å±•ï¼šk8s master èŠ‚ç‚¹çš„é«˜å¯ç”¨æ–¹æ¡ˆï¼›æ°´å¹³æ‰©ç¼©å®¹ï¼›å‚ç›´æ‰©ç¼©å®¹



## ä¸‰ã€æ“ä½œå‘½ä»¤

ä»»åŠ¡1ï¼šå°†æ¯ä¸ªèŠ‚ç‚¹çš„IPåœ°å€æ›´æ”¹ä¸ºéœ€æ±‚çš„ç½‘æ®µIP

```shell
Unable to connect to the server: dial tcp 10.3.201.100:6443: connect: no route to host --> (master) api_server é…ç½®æ²¡æœ‰æ›´æ–°

master -> 10.3.202.100 

# æ›´æ–° k8s masterèŠ‚ç‚¹ç›¸å…³é…ç½®æ–‡ä»¶ï¼Œå°†æ—§IPåœ°å€æ›´æ–°ä¸ºæ–°IPåœ°å€
  813  sed  -i 's/10.3.201/10.3.202/g' /etc/kubernetes/manifests/kube-apiserver.yaml
  815  sed  -i 's/10.3.201/10.3.202/g' /etc/kubernetes/manifests/etcd.yaml
  817  sed  -i 's/10.3.201/10.3.202/g' /etc/kubernetes/super-admin.conf
  818  sed  -i 's/10.3.201/10.3.202/g' /etc/kubernetes/admin.conf
  819  sed  -i 's/10.3.201/10.3.202/g' /etc/kubernetes/scheduler.conf
  820  sed  -i 's/10.3.201/10.3.202/g' /etc/kubernetes/manifests/etcd.yaml
  821  sed  -i 's/10.3.201/10.3.202/g' /etc/kubernetes/kubelet.conf

# æ£€æŸ¥ /etc/kubernetes/ ä¸å­˜åœ¨æ—§çš„IPåœ°å€
[root@master01 ~]# grep -nr  '201.100' /etc/kubernetes/*

# å‘ç° .kube/config é‡Œè¿˜æœ‰æŒ‡å‘æ—§ api_server çš„ipåœ°å€
[root@master01 ~]# ls -l .kube/config
-rw------- 1 root root 5652 Feb 19 10:34 .kube/config
sed  -i 's/10.3.201/10.3.202/g' .kube/config

# é‡å¯ docker æœåŠ¡å’Œ kubelet æœåŠ¡
 systemctl restart docker kubelet

# api_server & controller-manager & scheduler é»˜è®¤å®‰è£…åœ¨ kube-system å‘½åç©ºé—´ä¸‹
[root@master01 ~]# kubectl get pods -n kube-system -o wide | grep 100 

# æ£€æŸ¥ node èŠ‚ç‚¹ï¼Œä»… kubelet æœåŠ¡çš„é…ç½®éœ€è¦æ›´æ–°
sed  -i 's/10.3.201/10.3.202/g' /etc/kubernetes/kubelet.conf

# ca è¯ä¹¦éªŒè¯å¤±è´¥ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°ç”Ÿæˆæ–°çš„è¯ä¹¦
[root@master01 ~]# kubectl get nodes -o wide

# E0717 18:54:19.018747 1117322 memcache.go:265] couldn't get current server API group list: Get "https://10.3.202.100:6443/api?timeout=32s": tls: failed to verify certificate: x509: certificate is valid for 10.0.0.1, 10.3.201.100, not 10.3.202.100

# å¤‡ä»½é…ç½®æ–‡ä»¶
[root@master01 ~]# mv /etc/kubernetes/pki/apiserver.crt backup/
[root@master01 ~]# mv /etc/kubernetes/pki/apiserver.key backup/

## è¾“å‡º kubeadm init æ“ä½œæ—¶é»˜è®¤çš„æ¨¡ç‰ˆé…ç½®æ–‡ä»¶
[root@master01 ~]# kubeadm  config print init-defaults

## ä»…é‡æ–°ç”Ÿæˆ api_server çš„åˆå§‹åŒ–
[root@master01 ~]# kubeadm init phase certs apiserver
I0717 19:02:38.392738 1119172 version.go:256] remote version is much newer: v1.33.3; falling back to: stable-1.29
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local master01] and IPs [10.96.0.1 10.3.202.100]

## æµ‹è¯•éªŒè¯
[root@master01 ~]# kubectl get nodes -o wide
NAME       STATUS   ROLES           AGE    VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE                      KERNEL-VERSION                 CONTAINER-RUNTIME
master01   Ready    control-plane   148d   v1.29.2   10.3.202.100   <none>        Rocky Linux 9.4 (Blue Onyx)   5.14.0-427.13.1.el9_4.x86_64   docker://27.2.0
node01     Ready    <none>          148d   v1.29.2   10.3.202.101   <none>        Rocky Linux 9.4 (Blue Onyx)   5.14.0-427.13.1.el9_4.x86_64   docker://27.2.0
node02     Ready    <none>          148d   v1.29.2   10.3.202.102   <none>        Rocky Linux 9.4 (Blue Onyx)   5.14.0-427.13.1.el9_4.x86_64   docker://27.2.0

## è¿˜æœ‰ä¸€ç§åšæ³•å¤„ç†nodeèŠ‚ç‚¹ï¼Ÿï¼Ÿ å…ˆæŠŠnodeèŠ‚ç‚¹ä»é›†ç¾¤ä¸­è¸¢å‡ºå»ï¼Œè¸¢å‡ºå»ä¹‹åå†åŠ è¿›æ¥ã€‚
1. é©±é™¤å·¥ä½œèŠ‚ç‚¹ kubectl drain <node>
2. åˆ é™¤pod kubectl delete pod <node_ip>  (--all-namespaces)
3. è®¾ç½®ä¸ºä¸å¯è°ƒåº¦èŠ‚ç‚¹ï¼š kubectl uncordon <node>
4. kubeadm join xxxx 

## å·¥ä½œåœºæ™¯ï¼šæ¯”å¦‚æœ‰ä¸€å°k8sçš„nodeå‘ç”Ÿç‰©ç†æ•…éšœï¼ˆç½‘ç»œç»å¸¸æ€§æŠ–åŠ¨ ç›¸å¯¹äºå…¶ä»–èŠ‚ç‚¹ä¸Šçš„pod å»¶æ—¶ä¼šé«˜æˆ–è€…å¿½é«˜å¿½ä½ ï½œ cpu ï½œ mem ï¼‰ 

## ä¼˜é›…ä¸‹çº¿æœºå™¨ï¼Ÿ ç¡®ä¿podåœ¨å…¶ä»–nodeä¸Šæœ‰é‡æ–°åˆ›å»ºæ–°pod æš´åŠ›ä¸‹çº¿ï¼ˆxxxï¼‰
## kube-controller ç»„ä»¶ï¼Ÿï¼Ÿ  æ£€æŸ¥å½“å‰pod/å…¶ä»–apiå¯¹è±¡çš„å‰¯æœ¬æ•°é‡ æ˜¯å¦ è·Ÿé¢„æœŸçŠ¶æ€ä¸€è‡´ï¼Ÿ -> kube-scheduler é‡æ–°è°ƒåº¦ -> kubeletåœ¨å¯¹åº”çš„nodeèŠ‚ç‚¹ä¸Šåˆ›å»ºæ–°çš„pod
```



ä»»åŠ¡2ï¼šè§£å†³å®Œä¸Šè¿°æ‰€æœ‰å¼‚å¸¸ç°è±¡ï¼Œç„¶å kubectl get nodes -o wide å‘½ä»¤è¾“å‡ºçš„é›†ç¾¤ä¿¡æ¯æ˜¯æ­£å¸¸çš„

å¼‚å¸¸ç°è±¡ï¼š

1. k8sé›†ç¾¤ä¸Šè¿˜æœ‰å¾ˆå¤šå¼‚å¸¸çš„pod
   å‰¯æœ¬ä¸ç¬¦åˆé¢„æœŸçš„ï¼š
    kube-system   coredns-857d9ff4c9-26lmv                   0/1     Running            234 (5m40s ago)   148d
   STATUSæ˜¯ ï¼š ImagePullBackOffã€ImagePullBackOff éƒ½æ˜¯ä¸€äº›å¼‚å¸¸çš„ è¦æ€ä¹ˆå¤„ç†ï¼Ÿï¼Ÿ 
2. kube-system   calico-kube-controllers-558d465845-4blqv   0/1     CrashLoopBackOff   6 (104s ago)      148d
   æœ‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼ˆk8sçš„é›†ç¾¤ç½‘ç»œç»„ä»¶ï¼‰



ä»»åŠ¡3ï¼šæ¢å¤ kube-system é‡Œ calico ç»„ä»¶

```shell
[root@master01 ~]# kubectl get pods -n kube-system | grep calico
calico-kube-controllers-558d465845-4blqv   0/1     CrashLoopBackOff   8 (2m5s ago)      148d
calico-node-4t2zw                          0/1     Init:1/3           0                 8s
calico-node-sggl6                          0/1     Init:1/3           0                 8s
calico-node-tfvhv                          0/1     Init:1/3           0                 8s
calico-typha-5b56944f9b-gnrpr              1/1     Running            1 (18m ago)       148d

calico-node: æ¯ä¸ªèŠ‚ç‚¹ä¸Šéƒ½ä¼šéƒ¨ç½²ï¼Œè´Ÿè´£ç½‘ç»œçš„è½¬å‘ï¼Œæ•°æ®å±‚é¢
calico-kube-controllers : masterèŠ‚ç‚¹ä¸Šï¼Œè´Ÿè´£ç½‘ç»œæ§åˆ¶å±‚é¢

[root@master01 ~]# kubectl describe pod calico-node-4t2zw  -n kube-system | grep -A10 Events
Events:
  Type     Reason   Age                     From     Message

----     ------   ----                    ----     -------

  Warning  BackOff  5m9s (x10989 over 47h)  kubelet  Back-off restarting failed container install-cni in pod calico-node-4t2zw_kube-system(ce84e3b8-a32f-4f5b-86df-0bbdc1c01f46)

Pod æ˜¯ç”±ä¸€ä¸ª/å¤šä¸ª container 

calico-node 

- initContainers : åˆå§‹åŒ–containerï¼Œä¸€èˆ¬podåœ¨å¯åŠ¨è¿‡ç¨‹ä¸­ä¼šå…ˆç­‰å¾…init_containerè¿è¡ŒæˆåŠŸ
  upgrade-ipam
  install-cni
  mount-bpffs
- containers
  calico-node

è¦å­¦ä¼šé€šè¿‡æ—¥å¿—æ‰¾åˆ°é—®é¢˜
[root@master01 resources]# kubectl logs -n kube-system calico-node-4t2zw -c install-cni
W0719 11:42:34.766867       1 client_config.go:618] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work.
2025-07-19 11:42:34.777 [ERROR][1] cni-installer/<nil> <nil>: Unable to create token for CNI kubeconfig error=Unauthorized
2025-07-19 11:42:34.777 [FATAL][1] cni-installer/<nil> <nil>: Unable to create token for CNI kubeconfig error=Unauthorized

install-install -> api_server æƒé™æ˜¯ä¸æ˜¯æœ‰é—®é¢˜ï¼Ÿæœ‰æ²¡æœ‰é…ç½®æ­£ç¡®ï¼Ÿï¼Ÿ
[root@master01 resources]# kubectl logs calico-kube-controllers-558d465845-4blqv -n kube-system | grep -i err
2025-07-19 11:45:24.309 [ERROR][1] client.go 295: Error getting cluster information config ClusterInformation="default" error=Get "https://10.0.0.1:443/apis/crd.projectcalico.org/v1/clusterinformations/default": dial tcp 10.0.0.1:443: connect: no route to host
2025-07-19 11:45:24.309 [INFO][1] main.go 138: Failed to initialize datastore error=Get "https://10.0.0.1:443/apis/crd.projectcalico.org/v1/clusterinformations/default": dial tcp 10.0.0.1:443: connect: no route to host

10.0.0.1:443 -> api_serverå¯¹å†…çš„è®¿é—®åœ°å€ 
10.3.202.100:6443 -> å¯¹å¤–çš„è®¿é—®åœ°å€

# å°† kube-proxy é‡Œçš„æ—§IPåœ°å€æ›´æ”¹ä¸ºæ–°ï¼Œä¿å­˜é€€å‡ºåçƒ­åŠ è½½é…ç½®
kubectl edit cm -n kube-system kube-proxy

# åˆ é™¤æ—§ pod 
kubectl delete pod -n kube-system -l k8s-app=kube-proxy --force=true
kubectl delete pod -n kube-system -l k8s-app=calico-node --force=true
kubectl delete pod -n kube-system -l k8s-app=calico-kube-controllers --force=true

# å†å»è¿½è¸ªæ–°çš„æ—¥å¿—
[root@master01 resources]# kubectl logs -n kube-system calico-node-4stnd -c install-cni
2025-07-19 11:56:18.810 [ERROR][1] cni-installer/<nil> <nil>: Unable to create token for CNI kubeconfig error=Post "https://10.0.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/calico-cni-plugin/token": tls: failed to verify certificate: x509: certificate is valid for 10.96.0.1, 10.3.202.100, not 10.0.0.1
2025-07-19 11:56:18.812 [FATAL][1] cni-installer/<nil> <nil>: Unable to create token for CNI kubeconfig error=Post "https://10.0.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/calico-cni-plugin/token": tls: failed to verify certificate: x509: certificate is valid for 10.96.0.1, 10.3.202.100, not 10.0.0.1

# ä»…é‡æ–°ç”Ÿæˆ api_server çš„åˆå§‹åŒ–
[root@master01 ~]# kubeadm init phase certs apiserver
I0717 19:02:38.392738 1119172 version.go:256] remote version is much newer: v1.33.3; falling back to: stable-1.29
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local master01] and IPs [10.96.0.1 10.3.202.100] # SAN 10.96.0.1 10.3.202.100 è¿™ä¸¤ä¸ªIP 

# å†é‡æ–°ä¸Šç”Ÿæˆä¸€ä¸ªè¯ä¹¦
[root@master01 ~]# cat kubeadm_config.yaml
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs:
    - "10.3.202.100"
    - "10.0.0.1"

[root@master01 ~]# kubeadm init phase certs apiserver --config kubeadm_config.yaml
I0719 20:02:55.309534 2040872 version.go:256] remote version is much newer: v1.33.3; falling back to: stable-1.29
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local master01] and IPs [10.96.0.1 10.3.202.100 10.0.0.1]

[root@master01 ~]# kubectl logs -n kube-system  calico-kube-controllers-558d465845-nsp27
2025-07-19 12:05:48.772 [ERROR][1] client.go 295: Error getting cluster information config ClusterInformation="default" error=Get "https://10.0.0.1:443/apis/crd.projectcalico.org/v1/clusterinformations/default": dial tcp 10.0.0.1:443: connect: no route to host

## å°† cluster-info cm æ—§IPåœ°å€è½¬ä¸ºæ–°IP
[root@master01 ~]# kubectl edit cm cluster-info -n kube-public

## å®Œå…¨æ¸…ç†calicoç›¸å…³pod
[root@master01 ~]# kubectl delete pod $(kubectl get pods -A  | grep calico | awk '{print $2}') -n kube-system

[root@master01 ~]# kubectl get pods -A  | grep calico
kube-system   calico-kube-controllers-558d465845-xh7sd   1/1     Running            0                 4m37s
kube-system   calico-node-f4ncr                          1/1     Running            0                 4m36s
kube-system   calico-node-h7zl9                          1/1     Running            0                 4m36s
kube-system   calico-node-zg2bb                          1/1     Running            0                 4m36s
kube-system   calico-typha-5b56944f9b-fkbsc              1/1     Running            0                 4m36s
```



ä»»åŠ¡4: LNMPä¸šåŠ¡å¼‚å¸¸æ¢å¤

```shell
## æŒ‡å‘æœ¬é›†ç¾¤master01 nfsçš„éœ€æ±‚
ä½¿ç”¨v1ç‰ˆæœ¬çš„yamlæ–‡ä»¶ï¼š kubectl apply -f xxxx
[root@master01 ~]# cat 01.nginx_v1.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx
  name: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.26.3
        ports:
        - containerPort: 80
        volumeMounts:
        - name: html
          mountPath: /usr/share/nginx/html
        - name: config
          mountPath: /etc/nginx/conf.d
        startupProbe:
          httpGet:
            path: /
            port: 80
          failureThreshold: 30
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
      volumes:
      - name: html
        nfs:
          server: 10.3.205.100
          path: /root/data/nfs/html
      volumes:
      - name: config
        nfs:
          server: 10.3.205.100
          path: /root/data/nfs/nginx
      - name: html
        nfs:
          server: 10.3.205.100
          path: /root/data/nfs/html

---

apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  clusterIP: None
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 80

---

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-nginx
spec:
  rules:
  - host: bbs.iproute.cn
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nginx-service
            port:
              number: 80
  ingressClassName: nginx
  
## ä¸ºä»€ä¹ˆéœ€è¦å¢åŠ å¥åº·æ£€æŸ¥ï¼Ÿ é€šè¿‡Pod çš„statusçœ‹ç€æ˜¯running ä½†æ˜¯ä¸šåŠ¡å®é™…ä¸Šè®¿é—®æ˜¯æœ‰é—®é¢˜

## å½“åŠ ä¸Šå¥åº·æ£€æŸ¥å, åˆ¤æ–­å¥åº·æ£€æŸ¥æ˜¯å¦ç”Ÿæ•ˆï¼Ÿ
nginx-6f844478b4-sqcmm   0/1     Running            0

  Warning  Unhealthy  79s (x5 over 118s)  kubelet            Startup probe failed: HTTP probe failed with statuscode: 404

## phpfpm targetPort 900 -> 9000

## check nginx 
[root@master01 resources]# kubectl get pods -o wide
NAME                     READY   STATUS             RESTARTS        AGE     IP               NODE     NOMINATED NODE   READINESS GATES
mysql-5cbcfd9d85-q24qb   1/1     Running            0               22m     10.244.196.175   node01   <none>           <none>
nginx-6f844478b4-5whnc   1/1     Running            0               38s     10.244.140.127   node02   <none>           <none>
nginx-6f844478b4-hxrtd   1/1     Running            0               50s     10.244.140.126   node02   <none>           <none>
nginx-6f844478b4-pf84b   1/1     Running            3 (5m27s ago)   5m37s   10.244.196.177   node01   <none>           <none>
php-5b8ff558c8-7zgr9     1/1     Running            0               14m     10.244.140.125   node02   <none>           <none>
php-5b8ff558c8-g46sk     1/1     Running            0               14m     10.244.140.124   node02   <none>           <none>
php-5b8ff558c8-x4hr9     1/1     Running            0               14m     10.244.196.173   node01   <none>           <none>

# ingress-controllerï¼š svc (LoadBalancer)
[root@master01 resources]# kubectl get svc -A | grep ingress
ingress       ingress-nginx-controller             LoadBalancer   10.10.47.140    <pending>     80:30331/TCP,443:31980/TCP   150d
ingress       ingress-nginx-controller-admission   ClusterIP      10.10.236.175   <none>        443/TCP                      150d

# ingress èµ„æºå¯¹è±¡
[root@master01 resources]# kubectl get ingress
NAME            CLASS   HOSTS            ADDRESS   PORTS   AGE
ingress-nginx   nginx   bbs.iproute.cn             80      150d

# pod
[root@master01 resources]# kubectl get pods -A -o wide | grep ingress
ingress       ingress-nginx-controller-27rlh             1/1     Running            13 (2d23h ago)   150d    10.3.205.102     node02     <none>           <none>
ingress       ingress-nginx-controller-mqdll             1/1     Running            2 (3d ago)       150d    10.3.205.101     node01     <none>           <none>              /

# è®¿é—®æ–¹å¼1:
[root@master01 resources]# curl -I -H "Host: bbs.iproute.cn" 10.3.205.101:30331
HTTP/1.1 200 OK

# è®¿é—®æ–¹å¼2:
[root@master01 resources]# grep bbs /etc/hosts
10.3.205.101 bbs.iproute.cn
[root@master01 resources]# curl -I bbs.iproute.cn
HTTP/1.1 200 OK
```



ä»»åŠ¡5: MySQLå˜æ›´ç®¡ç†

```shell
# è¿™é‡Œå¹¶ä¸èƒ½ç›´æ¥å»æ›´æ–° mysql çš„å¯†ç ï¼Œä»…ä»…æ˜¯åœ¨podç¬¬ä¸€æ¬¡åˆ›å»ºåˆå§‹åŒ–çš„æ—¶å€™è®¾ç½®çš„ root å¯†ç 
env:
- name: MARIADB_ROOT_PASSWORD
  value: "123"

## è¿›å…¥ mysql å®¹å™¨å†…
[root@master01 ~]# kubectl get pod  -A | grep mysql
default       mysql-6c6797b497-r98zb
[root@master01 ~]# kubectl exec -it mysql-6c6797b497-r98zb -- /bin/bash
root@mysql-6c6797b497-r98zb:/# mysql -uroot -p123
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 47037
Server version: 10.3.39-MariaDB-1:10.3.39+maria~ubu2004 mariadb.org binary distribution
Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.
Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

# root ç”¨æˆ·å¯†ç æ›´æ–°
MariaDB [(none)]> ALTER USER 'root'@'localhost' IDENTIFIED BY '123456';
Query OK, 0 rows affected (0.000 sec)

MariaDB [(none)]> ALTER USER 'root'@'%' IDENTIFIED BY '123456';
Query OK, 0 rows affected (0.000 sec)

MariaDB [(none)]> FLUSH PRIVILEGES;
Query OK, 0 rows affected (0.000 sec)

# å‘ç° nginx pod å¥åº·æ£€æŸ¥å¤±è´¥
[root@master01 ~]# kubectl get pod -A | grep nginx
default       nginx-7885fdbbbb-2mcm5                     0/1     Running            1 (57s ago)     21h
default       nginx-7885fdbbbb-d6cjw                     0/1     Running            1 (55s ago)     21h
default       nginx-7885fdbbbb-g6g8g                     0/1     Running            1 (54s ago)     21h
10.3.202.101 - - [21/Jul/2025:10:40:50 +0000] "GET / HTTP/1.1" 503 4209 "-" "kube-probe/1.29" "-"

# å®¹å™¨å†…ï¼Ÿ NFSï¼Ÿ  NFS çš„è·¯å¾„ç›®å½•æœ‰æŒ‚è½½ç»™ POD
NFS é…ç½®ï¼š /root/data/nfs/php   -> POD: /usr/local/etc
NFS åº”ç”¨é¡¹ç›®ï¼š /root/data/nfs/html   ->  POD: /usr/share/nginx/html

# YAML è¿™ç§å£°æ˜å¼çš„æ–¹å¼ >> å‘½ä»¤è¡Œ

# app åº”ç”¨æ—¥å¿—åœ¨å“ªé‡Œï¼Ÿ é…ç½®åœ¨å“ªé‡Œï¼Ÿ -> å»ç ”å‘ -> çœ‹æ•´ä¸ªä»£ç é¡¹ç›®ç»“æ„ï¼ˆå­˜å‚¨çš„ä½ç½®ï¼‰
[root@master01 ~]# ls -l /root/data/nfs/html/data/log/
total 44
-rw-r--r-- 1 www-data tape     17187 Feb 21 09:09 202502_cplog.php
-rw-r--r-- 1 www-data tape      1548 Jul 21 18:39 202507_errorlog.php
-rw-r--r-- 1 www-data www-data     0 Feb 20 09:11 index.htm
-rw-r--r-- 1 www-data tape     17066 Feb 20 10:08 install.log

# å¤„ç†æŠ¥é”™çš„æµç¨‹ï¼šå‘Šè­¦ -> ç›‘æ§ -> çœ‹æ—¥å¿— -> æ˜ç¡®å®šä¹‰åˆ°æŸä¸€è¡Œä»£ç æŠ¥é”™ -> è‡ªå·±å°è¯•å¤ç°

# é”™è¯¯æ—¥å¿— 
<?PHP exit;?>	1753094940	<b>(0) notconnect</b><br><b>PHP:</b>index.php#require(%s):0136 -> forum.php#discuz_application->discuz_application->init():0057 -> source/class/discuz/discuz_application.php#discuz_application->discuz_application->_init_db():0066 -> source/class/discuz/discuz_application.php#discuz_database::discuz_database::init():0444 -> source/class/discuz/discuz_database.php#db_driver_mysqli->db_driver_mysqli->connect():0023 -> source/class/db/db_driver_mysqli.php#db_driver_mysqli->db_driver_mysqli->_dbconnect():0074 -> source/class/db/db_driver_mysqli.php#db_driver_mysqli->db_driver_mysqli->halt():0085 -> source/class/db/db_driver_mysqli.php#break():0222	087936707e83fa1c7c591bcfba36bb39	<b>User:</b> uid=0; IP=10.3.202.101; RIP:10.3.202.101 Request: /

# åº”ç”¨é¡¹ç›®å…³äº mysql é…ç½®é¡¹
[root@master01 ~]# grep -nrw '123' /root/data/nfs/html/* | head -n 5
grep: /root/data/nfs/html/data/ipdata/ipv6wry.dat: binary file matches
/root/data/nfs/html/config/config_global.php:9:$_config['db'][1]['dbpw'] = '123';
/root/data/nfs/html/config/config_ucenter.php:9:define('UC_DBPW', '123');

sed -i 's/123/123456/g' /root/data/nfs/html/config/config_global.php
sed -i 's/123/123456/g' /root/data/nfs/html/config/config_ucenter.php

# è®© php ç›¸å…³åº”ç”¨é‡å¯ä¸€ä¸‹ï¼Ÿ ç›´æ¥åˆ podï¼ˆå…¶ä»–è¿˜æœ‰æ›´å¥½çš„æ›´æ–°ç­–ç•¥ -> php é‡Œèƒ½å¤Ÿé€šè¿‡å¥åº·æ£€æŸ¥æ•è·åˆ° mysqlå¯†ç å˜æ›´åæ²¡æ³•æ­£å¸¸è®¿é—®ï¼‰

# æµ‹è¯•éªŒè¯
[root@master01 ~]# curl -I bbs.iproute.cn
HTTP/1.1 200 OK
```



ä»»åŠ¡6: RedisæŒä¹…åŒ–ç®¡ç†

```shell
# å‚è€ƒ 04.redis_v1.yaml æ–‡ä»¶, apply
## Output: mount.nfs: mounting 10.3.202.100:/root/data/nfs/redis/data failed, reason given by server: No such file or directory

mkdir -pv /root/data/nfs/redis/data

# è¿›å…¥å®¹å™¨å†™å…¥æµ‹è¯•æ•°æ®
kubectl exec -it $(kubectl get pods -l app=redis -o jsonpath='{.items[0].metadata.name}') -- redis-cli
> SET testkey "persistence_verified"
> SAVE

# æ–‡ä»¶æŒä¹…åŒ–
[root@master01 ~]# tree data/nfs/redis/data/
data/nfs/redis/data/
â”œâ”€â”€ appendonlydir
â”‚   â”œâ”€â”€ appendonly.aof.1.base.rdb
â”‚   â”œâ”€â”€ appendonly.aof.1.incr.aof
â”‚   â””â”€â”€ appendonly.aof.manifest
â””â”€â”€ dump.rdb

# åˆ é™¤ Pod è§¦å‘é‡å»ºåéªŒè¯æ•°æ®
kubectl delete pod $(kubectl get pods -l app=redis -o jsonpath='{.items[0].metadata.name}')
kubectl exec $(kubectl get pods -l app=redis -o jsonpath='{.items[0].metadata.name}') -- redis-cli GET testkey
persistence_verified
```



å‡ºç°äº†å¼‚å¸¸é—®é¢˜

```shell
#   Warning  Failed     21s               kubelet            Failed to pull image "redis:latest": Error response from daemon: Get "https://registry-1.docker.io/v2/": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)

# master01 & node01 & node02  /etc/docker/daemon.json é‡Œå…³äº insecure-registries & registry-mirrors åˆ æ‰å§ï¼ˆp.iproute.cn:6443æœåŠ¡å·²ç»ä¸‹çº¿ï¼‰

# é‡å¯ docker & daemon-reload
[root@master01 resources]# systemctl daemon-reload
[root@master01 resources]# systemctl restart docker

[root@master01 ~]# kubectl get nodes
Error from server (Forbidden): nodes is forbidden: User "kubernetes-admin" cannot list resource "nodes" in API group "" at the cluster scope

# Jul 21 19:36:28 master01 cri-dockerd[1130076]: time="2025-07-21T19:36:28+08:00" level=error msg="Error deleting pod kube-system/calico-kube-controllers-558d465845-xh7sd from network {docker 14f017f83f007856d784e497c3ce2a4>

# kubelet -> cri-docker -> docker 
```



ä»»åŠ¡7ï¼šæ–°å¢å·¥ä½œèŠ‚ç‚¹ï¼Œæ·»åŠ 1å°node

é€šè¿‡æœ‰è‡ªåŠ¨åŒ–é‡å¤æ€§çš„å·¥ä½œï¼Œå¯ä»¥å¤§å¹…æå‡æ•ˆç‡ï¼Œæ ‡å‡†åŒ–çš„æ“ä½œå¯ä»¥æº¯æºä¸ä¼šå› ä¸ºä¸ªäººè¯¯æ“ä½œè€Œäº§ç”Ÿé¢„æœŸå¤–çš„é—®é¢˜

1. å•èŠ‚ç‚¹ï¼šLAMP æ­å»º
2. å•èŠ‚ç‚¹ï¼šdocker ç¯å¢ƒçš„éƒ¨ç½²
3. å¤šèŠ‚ç‚¹ï¼š nginxä½œä¸ºLB + keepalived + webæœåŠ¡
4. K8sé›†ç¾¤çš„æ­å»ºï¼šå¤šèŠ‚ç‚¹éƒ¨ç½²

å¯¹äºè‡ªåŠ¨åŒ–å¤„ç†é‡å¤å·¥ä½œçš„æ€è·¯ï¼šshellï¼ˆå•ä¸ªshellæ–‡ä»¶å°½é‡ä¸è¦è¶…è¿‡100è¡Œï¼‰+ pythonï¼ˆæ›´å¤æ‚çš„é€»è¾‘ï¼ŒAPIæ¥å£çš„è°ƒç”¨ï¼‰+ ansibleï¼ˆè§„æ¨¡åŒ–1000+ åŸºæœ¬èƒ½å¤Ÿcoverä½ï¼‰+ python/go ï¼ˆå¹³å°åŒ–ï¼‰

```bash
#!/bin/bash
CURRENT_DIR=$(dirname "$0")
ROOT_DIR=$(cd "$CURRENT_DIR/.." && pwd)

# å¯¼å…¥æ—¥å¿—æ¨¡å—å’Œæ£€æŸ¥å·¥å…·æ¨¡å—
source $ROOT_DIR/logger.sh
source $ROOT_DIR/utils/utils.sh

# å¯¼å…¥åŸºç¡€å®‰è£…è„šæœ¬
source $ROOT_DIR/install/install_base.sh
run_base_install

# Check and execute join command
JOIN_SCRIPT="${ROOT_DIR}/join_command.sh"
if [ -f "$JOIN_SCRIPT" ]; then
    log_info "ğŸ”„ æ‰§è¡ŒèŠ‚ç‚¹åŠ å…¥å‘½ä»¤..."
    # Add containerd socket parameter to join command
    JOIN_CMD=$(cat "$JOIN_SCRIPT")
    JOIN_CMD="$JOIN_CMD --cri-socket unix:///var/run/cri-dockerd.sock"
    
    if eval "$JOIN_CMD"; then
        log_info "âœ… èŠ‚ç‚¹æˆåŠŸåŠ å…¥é›†ç¾¤"
    else
        log_error "âŒ èŠ‚ç‚¹åŠ å…¥å¤±è´¥"
        exit 1
    fi

else
    log_warn "âš ï¸ æ§åˆ¶èŠ‚ç‚¹ä¸Šæ‰§è¡Œ: kubeadm token create --print-join-command"
fi

log_info "ğŸ æ‰€æœ‰ç»„ä»¶å®‰è£…å®Œæˆï¼ŒKubernetesèŠ‚ç‚¹å°±ç»ª"
```



æ‰©å±•ï¼š

k8s master èŠ‚ç‚¹çš„é«˜å¯ç”¨æ–¹æ¡ˆï¼›

Keepalived + Load Balancer ï¼š LB å¯ä»¥æ˜¯ LVSã€Haproxy æˆ– Nginxï¼Œç»“åˆ keepalived å®ç°è´Ÿè½½å‡è¡¡é«˜å¯ç”¨ã€‚
Load Balancer æœåŠ¡ æ¥å—å‰å°ç”¨æˆ·å‘é€è¿‡æ¥çš„ kubectl ç­‰è¯·æ±‚ï¼Œå†é€šè¿‡åå‘ä»£ç†è½¬å‘åˆ°åå°çš„ Master èŠ‚ç‚¹ä¸Šé¢ï¼Œ
å•èŠ‚ç‚¹çš„è¯ï¼Œå¤šå° Node ç›´æ¥æŒ‡å‘ ä¸€å°Master èŠ‚ç‚¹ï¼›è€Œå¤šMasteré›†ç¾¤ç»“æ„ä¸­ï¼ŒMaster ä¼šæŒ‡å‘ Load Balancer æœåŠ¡ï¼Œè¯·æ±‚éƒ½æ¥è‡ªè´Ÿè½½å‡è¡¡æœåŠ¡ï¼Œæ‰€ä»¥LBè¦åšé«˜å¯ç”¨ã€‚
Master çš„ Apiserver éƒ½æŒ‡å‘ Keepalived çš„è™šæ‹Ÿ IPä¸Š
Master ä¸Šé€šè¿‡ Apiserver ç›´æ¥ æ“ä½œ Node èŠ‚ç‚¹ä¸Šçš„ kubeletï¼Œä¸éœ€è¦å†é€šè¿‡ VIP çš„è´Ÿè½½å‡è¡¡è½¬å‘ã€‚Node èŠ‚ç‚¹ä¼šç”± Master ç®¡ç†å®ç°é«˜å¯ç”¨ã€‚
é¦–å…ˆ ETCD é›†ç¾¤å®ç° å»ä¸­å¿ƒåŒ–é«˜å¯ç”¨ï¼ˆå¥‡æ•°å°æœºå™¨ï¼‰ï¼Œé€šè¿‡ Raft ç®—æ³•ä¿æŒæ•°æ®åº“æ•°æ®ä¸€è‡´æ€§ã€‚



æ°´å¹³æ‰©ç¼©å®¹ï¼š

HPA é€šè¿‡ç›‘æ§é¢„è®¾çš„æ€§èƒ½æŒ‡æ ‡ï¼Œå‘¨æœŸæ€§åœ°æ£€æŸ¥å½“å‰æŒ‡æ ‡å€¼æ˜¯å¦è¶…è¿‡è®¾å®šçš„é˜ˆå€¼ã€‚è‹¥è¶…è¿‡ï¼Œåˆ™æ ¹æ®ç®—æ³•è‡ªåŠ¨è°ƒæ•´ç›®æ ‡ Deploymentã€ReplicaSet æˆ– StatefulSet çš„å‰¯æœ¬æ•°é‡

hpaæ¨¡æ¿

åˆ›å»ºHPAèµ„æº

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-demo
spec:
  minReplicas: 1  #æœ€å°podæ•°é‡
  maxReplicas: 10 #æœ€å¤§podæ•°é‡
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 10 # åœ¨è¿ç»­10ç§’å†…ç¨³å®šåæ‰è€ƒè™‘è¿›ä¸€æ­¥æ‰©å±•æ“ä½œ
      policies:
      - type: Percent
        value: 100 # å½“è¶…è¿‡å½“å‰å‰¯æœ¬æ•°çš„100%æ‰è¿›è¡Œæ‰©å±• 
        periodSeconds: 3 # ä¸¤æ¬¡æ‰©å®¹ä¹‹é—´çš„æœ€å°æ—¶é—´é—´éš”
    scaleDown:
      stabilizationWindowSeconds: 300 # åœ¨è¿ç»­300ç§’å†…ç¨³å®šåæ‰è€ƒè™‘ç¼©å‡æ“ä½œ
      policies:
      - type: Percent
        value: 10 # å½“ä½äºå½“å‰å‰¯æœ¬æ•°çš„10%æ‰è¿›è¡Œç¼©å‡ 
        periodSeconds: 3 # ä¸¤æ¬¡ç¼©å‡ä¹‹é—´çš„æœ€å°æ—¶é—´é—´éš”
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 10 # CPUå¹³å‡åˆ©ç”¨ç‡ç›®æ ‡è®¾ä¸º10%
  scaleTargetRef:   # æŒ‡å®šè¦æ§åˆ¶çš„nginxä¿¡æ¯
    apiVersion: apps/v1
    kind: Deployment
    name: nginx
```



å‚ç›´æ‰©ç¼©å®¹
