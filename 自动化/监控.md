# Zabbix监控和Prometheus监控

## 一、Zabbix监控

### Zabbix监控简介

#### zabbix优点

- 开源,无软件成本投入
- Server 对设备性能要求低
- 支持设备多,自带多种监控模板
- 支持分布式集中管理,有自动发现功能,可以实现自动化监控
- 开放式接口,扩展性强,插件编写容易
- 当监控的 item 比较多服务器队列比较大时可以采用主动状态,被监控客户端主动 从server 端去下载需要监控的 item 然后取数据上传到 server 端。 这种方式对服务器的负载比较小。
- Api 的支持,方便与其他系统结合



#### zabbix缺点

- 需在被监控主机上安装 agent,所有数据都存在数据库里, 产生的数据很大,瓶颈主要在数据库。
- 项目批量修改不方便
- 社区虽然成熟，但是中文资料相对较少，服务支持有限；
- 入门容易，能实现基础的监控，但是深层次需求需要非常熟悉Zabbix并进行大量的二次定制开发难度较大
- 系统级别报警设置相对比较多，如果不筛选的话报警邮件会很多；并且自定义的项目报警需要自己设置，过程比较繁琐；
- 缺少数据汇总功能，如无法查看一组服务器平均值，需进行二次开发；



#### zabbix组件结构

- Zabbix_Server：整个监控体系中最核心的组件，它负责接收客户端发送的报告信息，所有配置、统计数据及操作 数据都由它组织。
- 数据库存储：所有配置信息和Zabbix收集到的数据都被存储在数据库中。
- Web界面：为了从任何地方和任何平台都可以轻松的访问Zabbix, 我们提供基于Web的Zabbix界面。该界面是 Zabbix Server的一部分，通常跟Zabbix Server运行在同一台物理机器上（！如果使用SQLite,Zabbix Web界面必 须要跟Zabbix Server运行在同一台物理机器上。）
- Zabbix_Proxy（可选）：用于监控节点非常多的分布式环境中，它可以代理zabbix-server的功能，减轻zabbixserver的压力。
- Zabbix_Agent：zabbix-agent为客户端软件，用于采集各监控项目的数据，并把采集的数据传输给zabbixproxy或zabbix-server。



#### zabbix监控方式

 **主动监控能极大节约监控server 的资源。**

- 被动模式：
  - 被动检测：相对于agent而言；agent, **server向agent请求获取配置的各监控项相关的数据**，agent接收请求、获取数据并响应给server；
  
- 主动模式
  - 主动检测：相对于agent而言；agent(active),**agent向server请求与自己相关监控项配置**，主动地将server配置的监控项相关的数据发送给server；
  



#### Zabbix常用术语

- 主机：一台你想监控的网络设备，用IP或域名表示
- 主机组：主机的逻辑组；它包含主机和模板。一个主机组里的主机和模板之间并没有任何直接的关联。通常在给不同用户组的主机分配权限时候使用主机组。
- 监控项：你想要接收的主机的特定数据，一个度量数据。
- 触发器：一个被用于定义问题阈值和“评估”监控项接收到的数据的逻辑表达式 当接收到的数据高于阈值时，触发器从“OK”变成“Problem”状态。当接收到的数据低于阈值时，触发器保留/返回一个“OK”的状态。



### Zabbix-server部署

#### 安装Zabbix 服务端

准备zabbix的yum源，这里通过安装zabbix-release软件包来自动获取zabbix的源。然后安装服务端相关组件

官网地址：https://www.zabbix.com/

```bash
[root@server1 ~]# rpm -Uvh https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-2.el7.noarch.rpm
[root@server1 ~]# yum install zabbix-server-mysql zabbix-web-mysql zabbix-agent -y
```

关闭防火墙和Selinux

```bash
[root@server1 ~]# setenforce 0
[root@server1 ~]# systemctl stop firewalld
```



##### 准备数据库环境

安装数据库，这里还是选择mariadb即可

创建zabbix所需数据库以及zabbix账户

```bash
# 创建zabbix库
MariaDB [(none)]> create database zabbix char set utf8 collate utf8_bin;
Query OK, 1 row affected (0.00 sec)
# 创建zabbix账户
MariaDB [(none)]> grant all privileges on zabbix.* to zabbix@localhost identified by  '123456';
Query OK, 0 rows affected (0.00 sec)
# 刷新账户信息
MariaDB [(none)]> flush privileges;
Query OK, 0 rows affected (0.00 sec)
MariaDB [(none)]> set global log_bin_trust_function_creators = 1;
```



##### 修改服务端相关配置

导入初始架构数据

```bash
[root@server1 ~]# zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -D zabbix -p123456   # zabbix安装包中有一个SQL文件，这是zabbix架构的初始数据。
[root@server1 ~]# mysql -uzabbix -p123456 -D zabbix -e "show tables"
+----------------------------+
| Tables_in_zabbix           |
+----------------------------+
| acknowledges               |
| actions                    |
| alerts                     |
| application_discovery      |
| application_prototype      |
| application_template       |
| applications               |
| auditlog                   |
| auditlog_details           |
| autoreg_host               |
......
......
......
[root@server1 ~]# mysql -uroot -p123456  -e "set global log_bin_trust_function_creators = 0;"
```

配置zabbix连接数据库

```bash
[root@server1 ~]# vim /etc/zabbix/zabbix_server.conf
DBPassword=123456
```

编辑zabbix网站中php的相关配置

```bash
[root@server1 ~]# vim /etc/httpd/conf.d/zabbix.conf
php_value max_execution_time 300
php_value memory_limit 128M
php_value post_max_size 16M
php_value upload_max_filesize 2M
php_value max_input_time 300
php_value always_populate_raw_post_data ‐1
php_value date.timezone Asia/Shanghai 

# 配置解释
设置 PHP 脚本的最大执行时间为 300 秒(5分钟)
设置 PHP 脚本的最大内存使用限制为 128 MB
设置 POST 请求的最大数据大小为 16 MB
设置上传文件的最大大小为 2 MB
设置 PHP 脚本接受输入的最大时间为 300 秒(5分钟)
设置 PHP 总是填充 $HTTP_RAW_POST_DATA 变量
设置 PHP 的时区为 Asia/Shanghai(中国时区)
```

启动所有服务

```bash
# 安装zabbix的时候，会附带按照httpd来提供web服务，因为zabbix默认情况下是有一个web网站的
[root@server1 ~]# systemctl restart zabbix-server httpd mariadb zabbix-agent
```



##### 服务端初始化

完成上述配置后，可以在浏览器中输入`http://IP/zabbix`打开zabbix的web界面开始初始化

登录zabbix的web网站时，**默认的username：Admin password：zabbix**



#### 客户端配置

在server2上安装zabbix-agent客户端

```bash
[root@server2 ~]# rpm -Uvh https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-2.el7.noarch.rpm
[root@server2 ~]# yum install zabbix-agent -y
```

##### 修改客户端配置文件

```bash
[root@server2 ~]# vim /etc/zabbix/zabbix_agentd.conf 
# 主要修改以下三个参数
Server=192.168.175.10
ServerActive=192.168.175.10
Hostname=server1
```

##### 启动zabbix-agent

```bash
[root@server2 ~]# setenforce 0
[root@server2 ~]# systemctl stop firewalld
[root@server2 ~]# systemctl start zabbix-agent.service
```



### 快速使用

#### 主机监控

先简单的监控一个主机的状态和信息

添加一个主机：在配置栏里选择主机选项，选择右上角的新建主机。填写主机信息

添加模板：zabbix内置了很多模板，比如监控Linux主机的模板，监控httpd的模板，监控MySQL的模板等等。我们可以直接使用这些模板，当然也可以自定义。一个模板中包含很多的应用集，每个应用集中又包含很多具体的监控项

创建应用集/主机群组：模板中内置的很多的监控项，但是如果没有我们想要的监控项的话，我们可以手动添加。先创建一个应用集，然后再应用集中创建监控项

创建监控项：创建好了test应用集以后，我们再向该应用集中添加具体的监控项。



#### 自定义配置监控项

##### 配置监控项文件

```bash
[root@server2 ~]# vim /etc/zabbix/zabbix_agentd.d/userparameter_nginx.conf 
UserParameter=nginx_process_num,ps aux | grep -c nginx

# 重启zabbix-agent
[root@server2 ~]# systemctl restart zabbix-agent
```



##### 服务端验证

可以在服务端上安装一个zabbix工具`zabbix-get`,可以通过该工具在命令行中验证监控项的是否生效

```bash
[root@server1 ~]# yum install -y zabbix-get
[root@server1 ~]# zabbix_get -s 192.168.88.20 -k nginx_process_num
7
```



##### 添加监控项

在web网站上使用刚刚编写的监控项，并检查刚添加的监控项状态是否为已启用。查看具体的检测到的数据，在菜单栏中点击监测->最新数据，然后过滤刚刚的监控项



##### 添加触发器

给该监控项添加触发器，让他能够出发警告通知

查看仪表盘可以看到这里有一个告警信息，说明我们刚刚创建的触发器生效了。

这样的话，运维工程师就可以直接在这个网站上看到当前服务器组或者集群中各个机器和服务的状态。 不需要在一个一个登录上去查看了。

但是只是这样还是不够只能，稍后我们将继续配置触发告警以后，通过邮件或者叮叮企业微信等平台向工程师发送告警信息。



### 常见服务的监控项

#### Redis自定义监控项

```bash
vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/redis.conf
UserParameter=Redis.Status,/usr/local/redis/bin/redis-cli -h 127.0.0.1 -p 6379 ping |grep -c PONG
UserParameter=Redis_conn[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w "connected_clients" | awk -F':' '{print $2}'
UserParameter=Redis_rss_mem[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w "used_memory_rss" | awk -F':' '{print $2}'
UserParameter=Redis_lua_mem[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w "used_memory_lua" | awk -F':' '{print $2}'
UserParameter=Redis_cpu_sys[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w "used_cpu_sys" | awk -F':' '{print $2}'
UserParameter=Redis_cpu_user[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w "used_cpu_user" | awk -F':' '{print $2}'
UserParameter=Redis_cpu_sys_cline[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w "used_cpu_sys_children" | awk -F':' '{print $2}'
UserParameter=Redis_cpu_user_cline[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w "used_cpu_user_children" | awk -F':' '{print $2}'
UserParameter=Redis_keys_num[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep -w "$$1" | grep -w "keys" | grep db$3 | awk -F'=' '{print $2}' | awk -F',' '{print $1}'
UserParameter=Redis_loading[*],/usr/local/redis/bin/redis-cli -h $1 -p $2 info | grep loading | awk -F':' '{print $$2}'

Redis.Status --检测Redis运行状态， 返回整数
Redis_conn  --检测Redis成功连接数，返回整数
Redis_rss_mem  --检测Redis系统分配内存，返回整数
Redis_lua_mem  --检测Redis引擎消耗内存，返回整数
Redis_cpu_sys --检测Redis主程序核心CPU消耗率，返回整数
Redis_cpu_user --检测Redis主程序用户CPU消耗率，返回整数
Redis_cpu_sys_cline --检测Redis后台核心CPU消耗率，返回整数
Redis_cpu_user_cline --检测Redis后台用户CPU消耗率，返回整数
Redis_keys_num --检测库键值数，返回整数
Redis_loding --检测Redis持久化文件状态，返回整数
```



#### Nginx自定义监控项

```bash
vim /etc/nginx/conf.d/default.conf
    location /nginx-status
    {
        stub_status on;
        access_log off;
        allow 127.0.0.1;
        deny all;
    }


vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/nginx.conf
UserParameter=Nginx.active,/usr/bin/curl -s "http://127.0.0.1:80/nginx-status" | awk '/Active/ {print $NF}'
UserParameter=Nginx.read,/usr/bin/curl -s "http://127.0.0.1:80/nginx-status" | grep 'Reading' | cut -d" " -f2
UserParameter=Nginx.wrie,/usr/bin/curl -s "http://127.0.0.1:80/nginx-status" | grep 'Writing' | cut -d" " -f4
UserParameter=Nginx.wait,/usr/bin/curl -s "http://127.0.0.1:80/nginx-status" | grep 'Waiting' | cut -d" " -f6
UserParameter=Nginx.accepted,/usr/bin/curl -s "http://127.0.0.1:80/nginx-status" | awk '/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ {print $1}'
UserParameter=Nginx.handled,/usr/bin/curl -s "http://127.0.0.1:80/nginx-status" | awk '/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ {print $2}'
UserParameter=Nginx.requests,/usr/bin/curl -s "http://127.0.0.1:80/nginx-status" | awk '/^[ \t]+[0-9]+[ \t]+[0-9]+[ \t]+[0-9]+/ {print $3}'
```



#### TCP协议自定义监控项

```bash
vim /usr/local/zabbix/share/zabbix/alertscripts/tcp_connection.sh
#!/bin/bash
function ESTAB { 
/usr/sbin/ss -ant |awk '{++s[$1]} END {for(k in s) print k,s[k]}' | grep 'ESTAB' | awk '{print $2}'
}
function TIMEWAIT {
/usr/sbin/ss -ant | awk '{++s[$1]} END {for(k in s) print k,s[k]}' | grep 'TIME-WAIT' | awk '{print $2}'
}
function LISTEN {
/usr/sbin/ss -ant | awk '{++s[$1]} END {for(k in s) print k,s[k]}' | grep 'LISTEN' | awk '{print $2}'
}
$1

vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/cattcp.conf
UserParameter=tcp[*],/usr/local/zabbix/share/zabbix/alertscripts/tcp_connection.sh $1

tcp[TIMEWAIT] --检测TCP的驻留数，返回整数
tcp[ESTAB]  --检测tcp的连接数、返回整数
tcp[LISTEN] --检测TCP的监听数，返回整数
```



#### 系统监控自带监控项

```bash
agent.ping 检测客户端可达性、返回nothing表示不可达。1表示可达
system.cpu.load --检测cpu负载。返回浮点数
system.cpu.util -- 检测cpu使用率。返回浮点数
vfs.dev.read -- 检测硬盘读取数据，返回是sps.ops.bps浮点类型，需要定义1024倍
vfs.dev.write -- 检测硬盘写入数据。返回是sps.ops.bps浮点类型，需要定义1024倍
net.if.out[br0] --检测网卡流速、流出方向，时间间隔为60S
net-if-in[br0] --检测网卡流速，流入方向（单位：字节） 时间间隔60S
proc.num[]  目前系统中的进程总数，时间间隔60s
proc.num[,,run] 目前正在运行的进程总数，时间间隔60S
###处理器信息
通过zabbix_get 获取负载值
合理的控制用户态、系统态、IO等待时间剋保证进程高效率的运行
系统态运行时间较高说明进程进行系统调用的次数比较多，一般的程序如果系统态运行时间占用过高就需要优化程序，减少系统调用
io等待时间过高则表明硬盘的io性能差，如果是读写文件比较频繁、读写效率要求比较高，可以考虑更换硬盘，或者使用多磁盘做raid的方案
system.cpu.swtiches --cpu的进程上下文切换，单位sps，表示每秒采样次数，api中参数history需指定为3
system.cpu.intr  --cpu中断数量、api中参数history需指定为3
system.cpu.load[percpu,avg1]  --cpu每分钟的负载值，按照核数做平均值(Processor load (1 min average per core))，api中参数history需指定为0
system.cpu.load[percpu,avg5]  --cpu每5分钟的负载值，按照核数做平均值(Processor load (5 min average per core))，api中参数history需指定为0
system.cpu.load[percpu,avg15]  --cpu每5分钟的负载值，按照核数做平均值(Processor load (15 min average per core))，api中参数history需指定为0
```



#### 自定义系统监控项

```bash
###内存相关
vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/catcarm.conf
UserParameter=ram.info[*],/bin/cat  /proc/meminfo  |awk '/^$1:{print $2}'
ram.info[Cached] --检测内存的缓存使用量、返回整数，需要定义1024倍
ram.info[MemFree] --检测内存的空余量，返回整数，需要定义1024倍
ram.info[Buffers] --检测内存的使用量，返回整数，需要定义1024倍

####TCP相关的自定义项
vim /usr/local/zabbix/share/zabbix/alertscripts/tcp_connection.sh
#!/bin/bash
function ESTAB { 
/usr/sbin/ss -ant |awk '{++s[$1]} END {for(k in s) print k,s[k]}' | grep 'ESTAB' | awk '{print $2}'
}
function TIMEWAIT {
/usr/sbin/ss -ant | awk '{++s[$1]} END {for(k in s) print k,s[k]}' | grep 'TIME-WAIT' | awk '{print $2}'
}
function LISTEN {
/usr/sbin/ss -ant | awk '{++s[$1]} END {for(k in s) print k,s[k]}' | grep 'LISTEN' | awk '{print $2}'
}
$1

vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/cattcp.conf
UserParameter=tcp[*],/usr/local/zabbix/share/zabbix/alertscripts/tcp_connection.sh $1

tcp[TIMEWAIT] --检测TCP的驻留数，返回整数
tcp[ESTAB]  --检测tcp的连接数、返回整数
tcp[LISTEN] --检测TCP的监听数，返回整数
```



### Zabbix告警配置

#### Zabbix通过邮件告警

##### 配置告警设置

配置E-mail参数

在上面菜单栏中选择管理->报警媒介类型

最后面的密码是在QQ邮箱中申请的**授权码**修改Admin用户的报警媒介，QQSMTP服务器为smtp.qq.com，服务器端口为465，

配置告警动作，当触发器被触发时，发送告警通知给指定的用户

这里定义如果触发告警，应该怎么处理，以及如果发送邮件，邮件的内容。当然也可以自定义告警信息



#### Zabbix通过钉钉告警

##### 添加群机器人

在钉钉群中添加自定义机器人，并且配置关键词。保存好Webhook，并且设置安全关键词

##### 创建python脚本

由于zabbix无法直接向钉钉发送告警信息，所以这里需要借助python脚本来实现，让zabbix调用python脚本来向机器人接口发送信息

安装requests模块

```bash
[root@server1 ~]# yum install -y python-requests
```

python脚本如下：

```bash
[root@server1 alertscripts]# cd /usr/lib/zabbix/alertscripts
[root@server1 alertscripts]# vim zabbix_send_ding.py 
#!/usr/bin/python
# -*- coding: utf-8 -*-
# Author: xxxxxxxx
import requests
import json
import sys
import os

headers = {'Content-Type': 'application/json;charset=utf-8'}
api_url = "https://oapi.dingtalk.com/robot/send?access_token=d68555399dc737c450c50ddac16ab6c529f3a99dc68bdf88ac60e88f1b4ef340"
def msg(text):
    json_text= {
    "msgtype": "text",
    "at": {
        "atMobiles": [
            "18888888888"
        ],
            "isAtAll": True
     },
     "text": {
        "content": text
     }
    }
    print requests.post(api_url,json.dumps(json_text),headers=headers).content

if __name__ == '__main__':
# 这里用发送关键字用来触发告警
    text = "告警"
# 使用sys.argv来接收一个参数，该参数是zabbix发送的消息
    text = sys.argv[1]
    msg(text)
```

测试脚本

```bash
# 如果手动测试脚本的话，需要把text = sys.argv[1]先注释了
[root@server1 alertscripts]# chmod a+x zabbix_send_ding.py
[root@server1 alertscripts]# ./zabbix_send_ding.py
{"errcode":0,"errmsg":"ok"}
```



##### 配置zabbix钉钉告警

添加告警媒介

因为我们使用的python脚本只接收一个参数（内容），所以只需要添加一个参数{ALERT.MESSAGE}即可

添加处理动作恢复操作。告警消息内容如下（仅供参考）：

```bash
【zabbix告警】
告警问题：{EVENT.NAME}
告警时间：{EVENT.DATE}-{EVENT.TIME}
告警主机：{HOST.NAME}
告  警  IP：{HOST.IP}
监控项目：{ITEM.NAME}
故障等级：{EVENT.SEVERITY}


【zabbix告警恢复】
恢复时间：{EVENT.DATE}-{EVENT.TIME}
告警名称：{EVENT.NAME}
告警主机：{HOST.NAME}
告  警  IP：{HOST.IP}
告警等级：{EVENT.SEVERITY}


【zabbix告警更新】
{USER.FULLNAME} {EVENT.UPDATE.ACTION} problem at {EVENT.UPDATE.DATE} {EVENT.UPDATE.TIME}.
{EVENT.UPDATE.MESSAGE}
```

最后报警媒介绑定用户，填写钉钉的手机号即可



## 二、prometheus监控

### prometheus简介

#### Prometheus的优势

- 由指标名称和和键/值对标签标识的时间序列数据组成的多维数据模型
- 强大的查询语言 PromQL
- 不依赖分布式存储；单个服务节点具有自治能力。
- 时间序列数据是服务端通过 HTTP 协议主动拉取获得的。
- 也可以通过中间网关来推送时间序列数据
- 可以通过静态配置文件或服务发现来获取监控目标。
- 支持多种类型的图表和仪表盘。



#### Prometheus的组件、架构

Prometheus Server 直接从监控目标中或者间接通过推送网关来拉取监控指标，它在本地存储所有抓取到的样本数据，并对此数据执行一系列规则，以汇总和记录现有数据的新时间序列或生成告警。可以通过 Grafana或者其他工具来实现监控数据的可视化。

Prometheus server是Prometheus架构中的**核心组件**，基于go语言编写而成，无第三方依赖关系，可以独立部署在物理服务器上、云主机、Docker容器内。主要用于收集每个目标数据，并存储为时间序列数据，对外可提供数据查询支持和告警规则配置管理。

Prometheus服务器可以对监控目标进行静态配置管理或者动态配置管理，**它将监控采集到的数据按照时间序列存储在本地磁盘的时序数据库中**（当然也支持远程存储），自身对外提供了自定义的PromQL语言，可以对数据进行查询和分析

**Client Library**是用于检测应用程序代码的客户端库。在监控服务之前，需要向客户端库代码添加检测实现Prometheus中metric的类型。

**Exporter（数据采集）**用于**输出被监控组件信息的HTTP**接口统称为Exporter（导出器）。目前互联网公司常用的组件大部分都有Expoter供**直接使用**，比如Nginx、MySQL、linux系统信息等。

**Pushgateway**是指用于支持短期临时或批量计划任务工作的汇聚节点。主要用于短期的job，此类存在的job时间较短，可能在Prometheus来pull之前就自动消失了。所以针对这类job，设计成可以直接向Pushgateway推送metric，这样Prometheus服务器端便可以定时去Pushgateway拉去metric。ushgateway是prometheus的一个组件，prometheus server默认是通过exporter主动获取数据（默认采取pull拉取数据），pushgateway则是通过被动方式推送数据到prometheus server，用户可以写一些自定义的监控脚本把需要监控的数据发送给pushgateway， 然后pushgateway再把数据发送给Prometheus server

**Alertmanager**主要用于处理Prometheus服务器端发送的alerts信息，对其去除重数据、分组并路由到正确的接收方式，发出**告警**，支持丰富的告警方式。

**Service Discovery：****动态发现**待监控的target，从而完成监控配置的重要组件，在容器环境中尤为重要，该组件目前由Prometheus Server内建支持



#### Prometheus适用于什么场景

Prometheus适用于记录**文本格式的时间序列**，它既适用于以机器为中心的监控，也适用于高度动态的面向服务的监控。Prometheus是专为提高系统可靠性而设计的，它可以在断电期间快速诊断问题，每个Prometheus Server都是相互独立的，不依赖于网络存储或者其他远程服务。当基础架构出现问题时，可以通过Prometheus快速定位故障点，而且不会消耗大量的基础架构资源。



#### Prometheus不适合什么场景

Prometheus非常重视可靠性，即使在出现故障的情况下，你也可以随时统计有关系统的可用系统信息。如果你需要百分之百的准确度，例如按请求数量计费，那么Prometheus可能不太适合你，因为它收集的数据可能**不够详细完整精确**。



### 相关概念

#### 数据模型

Prometheus所有采集的监控数据均以**指标的形式**保存在内置的时间序列数据库当中（TSDB）：属于同一**指标名称**、同一**标签**集合的、有**时间戳**标记的数据流。除了存储的时间序列，Prometheus还可以根据查询请求产生临时的、衍生的时间序列作为返回结果。



#### 指标名称和标签

每一条时间序列由指标名称（Metric Name）以及一组标签（键值对）唯一标识。其中指标的名称（Metric Name）可以反映被监控样本的含义（例如，http*request_total可以看出来表示当前系统接收到的http请求总量），指标名称只能由ASCII字符、数字、下划线以及冒号组成，同时必须匹配正则表达式`[a-zA-Z*:][a-zA-Z0-9_:]*`。

**注意**

冒号用来表示用户自定义的记录规则，不能在 exporter 中或监控对象直接暴露的指标中使用冒号来定义指标名称。

通过使用标签，Prometheus开启了强大的多维数据模型：对于相同的指标名称，通过不同标签列表的集合，会形成特定的度量维度实例（例如，所有包含度量名称为 `/api/tracks` 的 http 请求，打上 `method=POST` 的标签，就会形成具体的 http 请求）。查询语言在这些指标和标签列表的基础上进行过滤和聚合，改变任何度量指标上的任何标签值（包括添加或删除指标），都会创建新的时间序列。

标签的名称只能由ASCII字符、数字、以及下划线组成并满足正则表达式`[a-zA-Z_][a-zA-Z0-9_]*`。其中以 `__` 作为前缀的标签，是系统保留的关键字，只能在系统内部使用。标签的值则可以包含任何 `Unicode` 编码的字符。



#### 样本

在时间序列中的每一个点称为样本，样本由以下三部分组成：

- 指标（metric）：指标名称和描述当前样本特征的labelset；
- 时间戳：一个精确到时间毫秒的时间戳
- 样本值：一个浮点型数据表示当前样本的值



### 表示方式

通过如下表示方式表示指定名称和指定标签集合的时间序列

```
<metric name>{<label name>=<label value>, ...}
```

例如，指标名称为 `api_http_requests_total`，标签为 `method="POST"` 和 `handler="/messages"` 的时间序列可以表示为：

```
api_http_requests_total{method="POST", handler="/messages"}
```



#### 指标类型

Prometheus的客户端库中提供了**四种核心的指标类型**。但这些类型只是在客户端库（客户端可以根据不同的数据类型调用不同的api接口）和在线协议中，实际在Prometheus Server中并不对指标类型进行区分，而是简单地把这些指标统一视为无类型的时间序列



##### Counter计数器

Counter类型代表一种样本数据单调递增的指标，即**只增不减**，除非监控系统发生了重置。例如，你可以使用counter类型的指标表示服务请求总数、已经完成的任务数、错误发生的次数等。

counter类型数据可以让用户方便的了解事件发生的速率的变化，在PromQL内置的相关操作函数可以提供相应的分析，比如HTTP应用请求量来进行说明：

```
//通过rate()函数获取HTTP请求量的增长率
rate(http_requests_total[5m])
//查询当前系统中，访问量前10的HTTP地址
topk(10, http_requests_total)
```



##### Gauge仪表盘

Gauge类型代表一种样本数据可以任意变化的指标，即**可增可减**。Gauge通常用于像温度或者内存使用率这种指标数据，也可以表示能随时请求增加会减少的总数，例如当前并发请求的数量。

对于Gauge类型的监控指标，通过PromQL内置的函数delta（）可以获取样本在一段时间内的变化情况，例如，计算cpu温度在两小时内的差异：

```
delta(cpu_temp_celsius{host="zeus"}[2h])
```

还可以通过PromQL内置函数predict_linear（）基于简单线性回归的方式，对样本数据的变化趋势做出预测。例如，基于两小时的样本数据，来预测主机可用磁盘空间在4个小时之后的剩余情况

```
predict_linear(node_filesystem_free{job="node"}[2h], 4 * 3600) < 0
```



##### Histogram直方图

在大多数情况下人们都倾向于使用某些**量化指标的平均值**，例如cpu的平均使用率、页面的平均响应时间。这种方式的问题很明显，以系统api调用的平均响应时间为例：如果大多数api请求都维持在100ms的响应时间范围内，而个别请求的响应时间需要5秒，那么就会导致某些web页面的响应落到中位数的情况，而这种现象被称为**长尾问题**。

为了区分是平均的慢还是长尾的慢，最简单的方式就是按照请求延迟的范围进行分组。例如，统计延迟在0-10ms之间的请求数有多少而10-20ms之间的请求数又有多少。通过这种方式可以快速分析系统慢的原因。Histogram和Summary都是为了能够解决这样问题的存在，通过Histogram和Summary类型的监控指标我们可以快速了解监控样本的分布情况。

Histogram在一段时间范围内对数据进行采样（通常是请求持续时间或响应大小等），并将其计入可配置的存储桶（bucket）中，后续可通过指定区间筛选样本，也可以统计样本总数，最后一般将数据展示为直方图。



##### Summary摘要

Summary即概率图，类似于Histogram，常用于跟踪与时间相关的数据。典型的应用包括请求持续时间、响应大小等。Summary同样提供样本的count和sum功能；还提供quantiles功能，可以**按百分比划**分跟踪结果，例如，quantile取值0.95，表示取样本里的95%数据。Histogram需要通过_bucket计算quantile，而Summary直接存储了quantile的值。



#### Jobs和Instances

在Prometheus中，任何被采集的目标，即每一个暴露监控样本数据的HTTP服务都称为**一个实例instance**，**通常对应于单个进程**。而**具有相同采集目的实例集合称为作业job**。



### Prometheus部署

#### 二进制部署

下载prometheus的二进制包官网地址：https://prometheus.io/download/

```bash
[root@server1 ~]# wget https://github.com/prometheus/prometheus/releases/download/v2.47.0/prometheus-2.47.0.linux-amd64.tar.gz
```

获取软件包的哈希值，与官网提供的软件包的哈希值进行对比，保证下载的Prometheus软件包的完整性

```bash
[root@server1 ~]# sha256sum prometheus-2.47.0.linux-amd64.tar.gz 
277ad9f110ded8e326bc885848952941e839fa38dd3237e36415f0fa35a04424  prometheus-2.47.0.linux-amd64.tar.gz
```

解压软件包到指定目录

```bash
[root@server1 ~]# mkdir /data
[root@server1 ~]# tar -zxvf prometheus-2.47.0.linux-amd64.tar.gz  -C /data/
[root@server1 ~]# cd /data/
[root@server1 data]# chown -R root:root /data/prometheus-2.47.0.linux-amd64
[root@server1 data]# ln -sv prometheus-2.47.0.linux-amd64 prometheus
"prometheus" -> "prometheus-2.47.0.linux-amd64"
```



#### 检查配置文件

在Prometheus日常维护中，一定会对配置文件prometheus.yml进行再编辑操作，通常对Prometheus服务进行重新启动操作即可完成对配置文件的加载。当然也可以通过动态的热加载来更新prometheus.yml中的配置信息 查看进程id，向进程发送SIHHUP信号

```bash
# kill -HUP pid
```

通过HTTP API发送post请求到/-/reload

```bash
# curl -X POST http://localhost:9090/-/reload
```

- 检查配置文件的语法正确性

```bash
[root@server1 ~]# cd /data/prometheus
[root@server1 prometheus]# ls
console_libraries  consoles  data  LICENSE  NOTICE  prometheus  prometheus.yml  promtool
[root@server1 prometheus]# ./promtool check config prometheus.yml 
Checking prometheus.yml
  SUCCESS: 0 rule files found
```



#### 创建自启动脚本

```bash
[root@server1 ~]# vim /usr/lib/systemd/system/prometheus.service
[Unit]
Description=Prometheus Server
Documentation=https://prometheus.io/docs/introduction/overview/
After=network.target

[Service]
Type=simple
Restart=on-failure
ExecStart=/data/prometheus/prometheus \
    --config.file=/data/prometheus/prometheus.yml \
    --storage.tsdb.path=/data/prometheus/data \
    --web.listen-address=:9090 \
    --web.enable-lifecycle
ExecReload=/bin/kill -HUP $MAINPID

[Install]
WantedBy=multi-user.target
```

systemd重载配置以及启动prometheus

```bash
[root@server1 ~]# systemctl daemon-reload
[root@server1 ~]# systemctl start prometheus
[root@server1 prometheus]# ss -nlt
State      Recv-Q Send-Q  Local Address:Port                 Peer Address:Port
LISTEN     0      128                 *:22                              *:*
LISTEN     0      100         127.0.0.1:25                              *:*
LISTEN     0      128                :::22                             :::*
LISTEN     0      100               ::1:25                             :::*
LISTEN     0      128                :::9090                           :::*
```

浏览器访问测试



### Exporter

#### 简介

在Prometheus的核心组件中，Exporter是重要的组成部分，在实际中**监控样本数据的收集**都是由Exporter完成的，Prometheus服务器只需要定时从这些Exporter提供的HTTP服务获取数据即可。官方提供了多种常用的Exporter，比如用于对数据库监控的mysqld_exporter和redis_exporter等。

Exporter本质上是将收集的数据转化为对应的文本格式，并提供HTTP接口，供Prometheus定期采集数据。



#### Exporter类型

- 直接采集型
  - 这类Exporter直接内置了响应的应用程序，用于向Prometheus直接提供target数据支持。这样设计的好处是，可以更好地监控各自系统内部的运行状态，同时也适合更多自定义监控指标的项目实施。
- 间接采集型
  - 原始监控目标并不直接支持Prometheus，需要我们使用Prometheus提供的客户端库编写该监控目标的监控采集数据，用户可以将该程序独立运行，取获取指定的各类监控数据值。例如，由于Linux操作系统自身并不能直接支持Prometheus，用户无法从操作系统层面上直接提供对Prometheus的支持，因此单独提供Node Exporter，还有数据库或网站HTTP应用类等Exporter。



#### 文本数据格式

在Prometheus的监控环境中，所有返回监控样本数据的Exporter程序，均需要遵守Prometheus规范，即基于文本的数据格式，其特点是具有更好的跨平台和可读性。在windows上可以使用浏览器，或者在Linux上通过curl工具来获得采集数据



#### Linux主机监控

Prometheus社区很活跃，提供了非常多类型的Exporter。可以在官网中找到自己想要的Exporter并进行下载https://prometheus.io/download/

由于Linux操作系统自身并不支持Prometheus，所以Prometheus官方提供了go语言编写的Node Exporter来实现对Linux操作系统主机的监控数据采集。它提供了系统内部几乎所有的标准指标，如cpu、内存、磁盘空间、磁盘I/O、系统负载和网络带宽。另外它还提供了由内核公开的大量额外监控指标，从负载平均到主板温度等。

##### 安装Exporter

1. 下载node exporter的二进制包并解压

```bash
[root@server2 ~]# wget https://github.com/prometheus/node_exporter/releases/download/v1.8.2/node_exporter-1.8.2.linux-amd64.tar.gz
[root@server2 ~]# mkdir /data
[root@server2 ~]# tar -zxvf node_exporter-1.8.2.linux-amd64.tar.gz -C /data/
node_exporter-1.8.2.linux-amd64/
node_exporter-1.8.2.linux-amd64/NOTICE
node_exporter-1.8.2.linux-amd64/node_exporter
node_exporter-1.8.2.linux-amd64/LICENSE
[root@server2 ~]# cd /data/
[root@server2 data]# chown -R root:root node_exporter-1.8.2.linux-amd64/
[root@server2 data]# ln -sv node_exporter-1.8.2.linux-amd64 node_exporter
"node_exporter" -> "node_exporter-1.8.2.linux-amd64"
```

1. 启动node_exporter

```bash
[root@server2 node_exporter]# ./node_exporter
```



##### 关联Prometheus server

当启动node_exporter开始工作时，node_exporter和Prometheus server还没有进行关联，二者各自独立没有关联。

可以在Prometheus server中，找到主机目录，找到主配置文件，使用其中的静态配置功能static_configs来采集node_exporter提供的数据

**server主配置文件介绍：**

```bash
[root@server1 prometheus]# cat prometheus.yml
# my global config
global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
      - targets: ["localhost:9090"]


==================================================================================
# 配置文件解释
global:
  scrape_interval：每次数据采集的时间间隔，默认为1分钟
  scrape_timeout：采集请求超时时间，默认为10秒
  evaluation_interval：执行rules的频率，默认为1分钟
scrape_configs：主要用于配置被采集数据节点操作，每一个采集配置主要由以下几个参数
  job_name：全局唯一名称
    scrape_interval：默认等于global内设置的参数，设置后可以覆盖global中的值
    scrape_timeout：默认等于global内设置的参数
    metrics_path：从targets获取meitric的HTTP资源路径，默认是/metrics
    honor_labels：Prometheus如何处理标签之间的冲突。若设置为True，则通过保留变迁来解决冲突；若设置为false，则通过重命名；
    scheme：用于请求的协议方式，默认是http
    params：数据采集访问时HTTP URL设定的参数
    relabel_configs：采集数据重置标签配置
    metric_relabel_configs：重置标签配置
    sample_limit：对每个被已知样本数量的每次采集进行限制，如果超过限制，该数据将被视为失败。默认值为0，表示无限制
```

- 直接编辑主配置文件，添加job与node_exporter关联

```bash
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
      - targets: ["localhost:9090"]
  - job_name: "node_exporter"
    static_configs:
      - targets: ["192.168.88.20:9100"]
```

- 检查配置文件并且重启服务

```bash
[root@server1 prometheus]# ./promtool check config prometheus.yml
Checking prometheus.yml
 SUCCESS: prometheus.yml is valid prometheus config file syntax

[root@server1 prometheus]# systemctl restart prometheus
[root@server1 prometheus]# ss -nlt
State      Recv-Q Send-Q            Local Address:Port                           Peer Address:Port
LISTEN     0      128                           *:22                                        *:*
LISTEN     0      100                   127.0.0.1:25                                        *:*
LISTEN     0      128                          :::22                                       :::*
LISTEN     0      100                         ::1:25                                       :::*
LISTEN     0      128                          :::9090                                     :::*
```

##### 查看Targets

重启服务即可成功关联

metricts数据采集



#### MySQL监控

##### 部署MySQL环境

```bash
# 创建exporter用户
ariaDB [(none)]> grant all privileges on *.* to mysqld_exporter@'%' identified by  '123456';
Query OK, 0 rows affected (0.00 sec)
# 刷新账户信息
MariaDB [(none)]> flush privileges;
Query OK, 0 rows affected (0.00 sec)
```

##### 安装Exporter

官网下载mysqld_exporter二进制包解压缩

```bash
[root@server2 ~]# wget https://github.com/prometheus/mysqld_exporter/releases/download/v0.15.1/mysqld_exporter-0.15.1.linux-amd64.tar.gz
[root@server2 ~]# tar -zxvf  mysqld_exporter-0.15.1.linux-amd64.tar.gz -C /data/
mysqld_exporter-0.15.1.linux-amd64/
mysqld_exporter-0.15.1.linux-amd64/LICENSE
mysqld_exporter-0.15.1.linux-amd64/mysqld_exporter
mysqld_exporter-0.15.1.linux-amd64/NOTICE
[root@server2 ~]# cd /data/
[root@server2 data]# chown -R root:root mysqld_exporter-0.15.1.linux-amd64/
[root@server2 data]# ln -sv  mysqld_exporter-0.15.1.linux-amd64/ mysqld_exporter
"mysqld_exporter" -> "mysqld_exporter-0.15.1.linux-amd64/"
```

##### 配置Exporter

```bash
[root@server2 mysqld_exporter]# pwd
/data/mysqld_exporter

# 创建一个配置文件.mysqld_exporter.cnf
[root@server2 mysqld_exporter]# vim .mysqld_exporter.cnf
[client]
user=mysqld_exporter
password=1

[root@server2 mysqld_exporter]# ./mysqld_exporter --config.my-cnf='.mysqld_exporter.cnf' &
[root@server2 mysqld_exporter]# ss -nlt
State      Recv-Q Send-Q Local Address:Port               Peer Address:Port     
LISTEN     0      50           *:3306                     *:*
LISTEN     0      128          *:22                       *:*
LISTEN     0      100    127.0.0.1:25                       *:*                 
LISTEN     0      128         :::9100                    :::*
LISTEN     0      128         :::9104                    :::*
LISTEN     0      128         :::22                      :::*
LISTEN     0      100        ::1:25                      :::*
```

##### 关联Prometheus server

```bash
[root@server1 prometheus]# vim prometheus.yml
 - job_name: 'mysqld_exporter'
    scrape_interval: 10s
    static_configs:
      - targets: [192.168.88.20:9104]

[root@server1 prometheus]# ./promtool check config prometheus.yml
Checking prometheus.yml
 SUCCESS: prometheus.yml is valid prometheus config file syntax

[root@server1 prometheus]# systemctl restart prometheus
```

metricts数据采集

### 服务发现

Prometheus服务发现能够自动化检测分类，并且能够识别新目标和变更目标。也就是说，可以自动发现并监控目标或变更目标，动态进行数据采集和处理。

#### 基于文件的服务发现

- 准备JSON格式的文件

```bash
[root@server1 ~]# cd /data/prometheus
[root@server1 prometheus]# mkdir targets
[root@server1 prometheus]# vim targets/dev_node.json
[{
    "targets": [ "192.168.175.20:9100","192.168.175.20:9104" ],
    "labels": {
         "env": "dev_webgame"
        }
}]
-------------------------------------------------------------------
或者这里是准备yaml文件，那么下面相应的配置文件需要与yaml匹配
vim targets/dev_node.yml
- targets:
  - "192.168.175.20:9100"
  - "192.168.175.20:9104"
```

- 修改配置文件

```bash
[root@server1 prometheus]# vim /data/prometheus/prometheus.yml 
  - job_name: 'node_service_discovery'
    file_sd_configs:
      - files:
        - targets/*.yml
        refresh_interval: 60m
```

- 重新启动服务

扩展：这是基于文件发现，还有基于consul基于dns的服务发现，这个自行扩展。



### PromQL

Prometheus提供了一种功能强大的表达式语言PromQL（Prometheus Query Language）。Prometheus允许用户实时选择和汇聚时间序列数据，是Prometheus自己开发的数据查询语言，使用这个查询语言能够进行各种聚合、分析和计算，使管理员能够根据指标更好地了解系统性能。



#### 时序数据库

首先Prometheus是一款时序数据库TSDB，它结合生态系统内的其他组件例如Pushgateway、Alertmanager等可构成一个完整的IT监控系统。

时序数据库的特点如下：

- 数据写入特点——写入平稳、持续、高并发高吞吐；写多读少，在写操作上数据上能达到95%以上；无更新时写入最近生成的数据
- 数据查询特点——按时间范围读取一段时间的数据；对最近生成的数据读取概率高，对历史数据查询概率低；按照数据点的不同密集度实现多精度查询
- 数据存储特点——数据存储量比较大；具有时效性，数据通常会有一个保存周期，多精度数据存储

对时序数据库的基本要求如下：

- 能够支持高并发、高吞吐的写入
- 交互及的聚合查询，能够达到低查询延迟
- 依据场景设计可以支持海量数据存储
- 在线应用服务场景中，需要高可用架构支持
- 针对写入和存储量的要求，应用环境底层需要分布式架构支持



##### 时序数据

**时间序列数据**：按照时间顺序记录系统、设备状态变化的数据，每个数据称为一个样本

数据采集以特定的时间周期进行，随着时间的流逝，将这些样本数据记录下来，将生成一个离散的样本数据序列

把该序列称作为**向量**，而将多个序列放在同一个坐标系内（以时间为横轴，以序列为纵轴，将形成一个有数据点组成的矩阵）

- **即时向量**：特定或全部的时间序列上的集合，具有相同时间戳的一组样本称之为即时向量
- **范围向量**：特定或全部的时间序列上的集合，在指定的同一时间范围内的所有样本值称之为范围向量

##### 时间序列选择器

即时向量选择器

即时向量选择器由两部分组成

- **指标名称**：用于限定特定指标下的时间序列，即负责过滤指标，可选
- **匹配器**：或称为标签选择器，用于过滤时间序列上的标签，定义在{}中
- 常见使用举例
  - prometheus_http_requests_total，仅给定指标名称
  - {job="node_exporter"}，仅给定匹配器
  - up{job="node_exporter"}，指标名称和匹配器的组合

匹配器用于定义标签过滤的条件，目前支持如下四种

- =：相等匹配模式，用来指定返回的时间序列与指定的标签完全匹配
- !=：反向匹配模式，即不等于模式
- =~：正则表达式匹配模式
- !~：反向正则表达式

范围向量选择器

同即时向量选择器唯一不同的地方在于，范围向量选择器需要在表达式后紧跟一个方括号[]来表达需要在时序上返回的样本所处的时间范围

时间范围：以当前时间为基准点，指向过去一个特定的时间长度，例如[5m]，便是指过去5分钟之内

可用的时间单位有：

- ms
- s
- m
- h
- d
- w
- y

**必须使用整数时间**，例如1h30m，但不允许使用1.5h

需要注意的是，范围向量选择器返回的是一定时间范围内的数据样本，虽然不同时间序列的数据抓点时间点相同，但特们的时间戳并不会严格对齐。多个target上的数据抓取需要分散在抓取时间点的周围，他们的时间戳并不会严格对齐，目的是为了均衡Prometheus的负载

因而，Prometheus在趋势上准确，但并非绝对精准



偏移量修改器

默认情况下，即时向量选择器和范围向量选择器都以当前时间为基准，而偏移量修改器能够修改该基准

例如：

up{job="node_exporter"}[5m]表示的是获取过去5分钟的即时样本

up{job="node_exporter"}[5m] offset 1d表示的是获取过去1天的即时样本



#### PromQL操作符

##### 数学运算

PromQL支持的所有数学运算符如下所示：

- `+` (加法)
- `-` (减法)
- `*` (乘法)
- `/` (除法)
- `%` (求余)
- `^` (幂运算)

##### 布尔运算

目前，Prometheus支持以下布尔运算符如下：

- `==` (相等)
- `!=` (不相等)
- `>` (大于)
- `<` (小于)
- `>=` (大于等于)
- `<=` (小于等于)

##### 集合运算符

使用瞬时向量表达式能够获取到一个包含多个时间序列的集合，我们称为瞬时向量。 通过集合运算，可以在两个瞬时向量与瞬时向量之间进行相应的集合操作。目前，Prometheus支持以下集合运算符：

- `and` (并且，交集)
- `or` (或者，并集)
- `unless` (差集)

***vector1 and vector2\*** 会产生一个由vector1的元素组成的新的向量。该向量包含vector1中完全匹配vector2中的元素组成。

***vector1 or vector2\*** 会产生一个新的向量，该向量包含vector1中所有的样本数据，以及vector2中没有与vector1匹配到的样本数据。

***vector1 unless vector2\*** 会产生一个新的向量，新向量中的元素由vector1中没有与vector2匹配的元素组

##### 操作符优先级

在PromQL操作符中优先级由高到低依次为：

1. `^`
2. `*, /, %`
3. `+, -`
4. `==, !=, <=, <, >=, >`
5. `and, unless`
6. `or`



#### PromQL聚合操作

Prometheus还提供了下列内置的聚合操作符，这些操作符作用域瞬时向量。可以将瞬时表达式返回的样本数据进行聚合，形成一个新的时间序列。

- `sum` (求和)
- `min` (最小值)
- `max` (最大值)
- `avg` (平均值)
- `stddev` (标准差)
- `stdvar` (标准差异)
- `count` (计数)
- `count_values` (对value进行计数)
- `bottomk` (后n条时序)
- `topk` (前n条时序)
- `quantile` (分布统计)

使用聚合操作的语法如下：

```
<aggr-op>([parameter,] <vector expression>) [without|by (<label list>)]
```

其中只有`count_values`, `quantile`, `topk`, `bottomk`支持参数(parameter)。

**without**用于从计算结果中**移除列举的标签，而保留其它标签**。by则正好相反，结果向量中**只保留列出的标签，其余标签则移除**。通过without和by可以按照样本的问题对数据进行聚合。



#### 向量匹配

##### one-to-one

一对一向量匹配模式，它从运算符的两侧表达式中获取**即时向量**，依次比较并找到一对唯一条目进行匹配，如果两个条目具有完全相同的标签和对应的值，则他们匹配。

在操作符两边表达式标签不一致的情况下，可以使用on(label list)或者ignoring(label list）来修改便签的匹配行为。使用ignoreing可以在匹配时忽略某些便签。而on则用于将匹配行为限定在某些便签之内。

```
<vector expr> <bin-op> ignoring(<label list>) <vector expr>
<vector expr> <bin-op> on(<label list>) <vector expr>
```

例如当存在样本：

```
method_code:http_errors:rate5m{method="get", code="500"}  24
method_code:http_errors:rate5m{method="get", code="404"}  30
method_code:http_errors:rate5m{method="put", code="501"}  3
method_code:http_errors:rate5m{method="post", code="500"} 6
method_code:http_errors:rate5m{method="post", code="404"} 21

method:http_requests:rate5m{method="get"}  600
method:http_requests:rate5m{method="del"}  34
method:http_requests:rate5m{method="post"} 120
```

使用PromQL表达式：

```
method_code:http_errors:rate5m{code="500"} / ignoring(code) method:http_requests:rate5m
```

该表达式会返回在过去5分钟内，HTTP请求状态码为500的在所有请求中的比例。如果没有使用ignoring(code)，操作符两边表达式返回的瞬时向量中将找不到任何一个标签完全相同的匹配项。

因此结果如下：

```
{method="get"}  0.04            //  24 / 600
{method="post"} 0.05            //   6 / 120
```

##### many-to-one和one-to-many

多对一和一对多的匹配模式，可以理解为向量元素中的一个样本数据匹配到了多个样本数据标签。在使用该匹配模式时，需要使用group_left或者group_right修饰符明确指定哪一个向量具有更高的基数，也就是**说左或者右决定了哪边的向量具有较高的子集**

```
<vector expr> <bin-op> ignoring(<label list>) group_left(<label list>) <vector expr>
<vector expr> <bin-op> ignoring(<label list>) group_right(<label list>) <vector expr>
<vector expr> <bin-op> on(<label list>) group_left(<label list>) <vector expr>
<vector expr> <bin-op> on(<label list>) group_right(<label list>) <vector expr>
```

多对一和一对多两种模式一定是出现在操作符两侧表达式返回的向量标签不一致的情况。因此需要使用ignoring和on修饰符来排除或者限定匹配的标签列表。

例如,使用表达式：

```
method_code:http_errors:rate5m / ignoring(code) group_left method:http_requests:rate5m
```

该表达式中，左向量`method_code:http_errors:rate5m`包含两个标签method和code。而右向量`method:http_requests:rate5m`中只包含一个标签method，因此匹配时需要使用ignoring限定匹配的标签为code。 在限定匹配标签后，右向量中的元素可能匹配到多个左向量中的元素 因此该表达式的匹配模式为多对一，需要使用group修饰符group_left指定左向量具有更好的基数。

最终的运算结果如下：

```
{method="get", code="500"}  0.04            //  24 / 600
{method="get", code="404"}  0.05            //  30 / 600
{method="post", code="500"} 0.05            //   6 / 120
{method="post", code="404"} 0.175           //  21 / 120
```



#### 内置函数

##### 计算Counter指标增长率

通过增长率表示样本的变化情况

increase(v range-vector)函数是PromQL中提供的众多内置函数之一。其中参数v是一个区间向量，increase函数获取区间向量中的第一个后最后一个样本并返回其增长量。因此，可以通过以下表达式Counter类型指标的增长率：

```
increase(node_cpu_seconds_total[2m] )/120
```

这里通过node_cpu[2m]获取时间序列最近两分钟的所有样本，**increase计算出最近两分钟的增长量，最后除以时间120秒得到node_cpu样本在最近两分钟的平均增长率。**并且这个值也近似于主机节点最近两分钟内的平均CPU使用率。

除了使用increase函数以外，PromQL中还直接内置了rate(v range-vector)函数，rate函数可以直接计算区间向量v在时间窗口内平均增长速率。因此，通过以下表达式可以得到与increase函数相同的结果：

```
rate(node_cpu_seconds_total[2m])
```

需要注意的是使用rate或者increase函数去计算样本的平均增长速率，**容易陷入“长尾问题”当中**，其无法反应在时间窗口内样本数据的突发变化。 例如，对于主机而言在2分钟的时间窗口内，可能在某一个由于访问量或者其它问题导致CPU占用100%的情况，但是通过计算在时间窗口内的平均增长率却无法反应出该问题。

为了解决该问题，PromQL提供了另外一个灵敏度更高的函数irate(v range-vector)。irate同样用于计算区间向量的计算率，但是其反应出的是**瞬时增长率**。irate函数是通过区间向量**中最后两个样本数据**来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的“长尾问题”，并且体现出更好的灵敏度，通过irate函数绘制的图标能够更好的反应样本数据的瞬时变化状态。

```
irate(node_cpu_seconds_total[2m])
```

irate函数相比于rate函数提供了更高的灵敏度，不过当需要分析长期趋势或者在告警规则中，irate的这种灵敏度反而容易造成干扰。因此在长期趋势分析或者告警中**更推荐使用rate函数**。

##### 预测Gauge指标变化趋势

在一般情况下，系统管理员为了确保业务的持续可用运行，会针对服务器的资源设置相应的告警阈值。例如，当磁盘空间只剩512MB时向相关人员发送告警通知。 这种基于阈值的告警模式对于当资源用量是平滑增长的情况下是能够有效的工作的。 但是如果资源不是平滑变化的呢？ 比如有些某些业务增长，存储空间的增长速率提升了高几倍。这时，如果基于原有阈值去触发告警，当系统管理员接收到告警以后可能还没来得及去处理问题，系统就已经不可用了。 因此阈值通常来说不是固定的，需要定期进行调整才能保证该告警阈值能够发挥去作用。 那么还有没有更好的方法吗？

PromQL中内置的predict_linear(v range-vector, t scalar) 函数可以帮助系统管理员更好的处理此类情况，predict_linear函数可以预测时间序列v在t秒后的值。它基于简单线性回归的方式，对时间窗口内的样本数据进行统计，从而可以对时间序列的变化趋势做出预测。**例如，基于2小时的样本数据，来预测主机可用磁盘空间的是否在4个小时候被占满，可以使用如下表达式：**

```
predict_linear(node_filesystem_free_bytes{job="node-exporter"}[2h], 4 * 3600) < 0
```

##### 统计Histogram指标的分位数

在本章的第2小节中，我们介绍了Prometheus的四种监控指标类型，其中Histogram和Summary都可以同于统计和分析数据的分布情况。区别在于Summary是直接在客户端计算了数据分布的分位数情况。而Histogram的分位数计算需要通过histogram_quantile(φ float, b instant-vector)函数进行计算。其中φ（0<φ<1）表示需要计算的分位数，如果需要计算中位数φ取值为0.5，以此类推即可。

以指标http_request_duration_seconds_bucket为例：

```
# HELP http_request_duration_seconds request duration histogram
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{le="0.5"} 0
http_request_duration_seconds_bucket{le="1"} 1
http_request_duration_seconds_bucket{le="2"} 2
http_request_duration_seconds_bucket{le="3"} 3
http_request_duration_seconds_bucket{le="5"} 3
http_request_duration_seconds_bucket{le="+Inf"} 3
http_request_duration_seconds_sum 6
http_request_duration_seconds_count 3
```

当计算9分位数时，使用如下表达式：

```
histogram_quantile(0.5, http_request_duration_seconds_bucket)
```

通过对Histogram类型的监控指标，用户可以轻松获取样本数据的分布情况。同时分位数的计算，也可以非常方便的用于评判当前监控指标的服务水平。

获取分布直方图的中位数

需要注意的是通过histogram_quantile计算的分位数，**并非为精确值**，而是通过http_request_duration_seconds_bucket和http_request_duration_seconds_sum**近似计算**的结果。



### Grafana数据展示

grafana是一款图形显示非常优秀的工具，支持图表模板导入，支持除Prometheus之外多种数据源（包括MySQL、zabbix、elasticsearch等等）

#### 部署Grafana

1. 下载软件包并且安装，官网地址：https://grafana.com/grafana/download

```bash
[root@server1 ~]# wget https://dl.grafana.com/oss/release/grafana-7.5.3-1.x86_64.rpm
[root@server1 ~]# yum install -y grafana-7.5.3-1.x86_64.rpm
```

1. 启动Grafana

```bash
[root@server1 ~]# systemctl start grafana-server
# 检查3000端口是否监听
[root@server1 ~]# ss -nlt
State      Recv-Q Send-Q            Local Address:Port                           Peer Address:Port
LISTEN     0      128                           *:22                                        *:*
LISTEN     0      100                   127.0.0.1:25                                        *:*
LISTEN     0      128                          :::22                                       :::*
LISTEN     0      128                          :::3000                                     :::*
LISTEN     0      100                         ::1:25                                       :::*
LISTEN     0      128                          :::9090                                     :::*
```

#### 访问Grafana

首次登陆用户名密码为admin admin

登录以后会提示修改密码

#### 使用Grafana

- 添加数据源

- 连接Prometheus

- 添加数据展示(Dashboard)

- 添加成功以后，就可以在首页中看到我们的数据展示了

#### 使用第三方模板

自己创建图表展示比较麻烦，我们可以直接使用别人以及做好的模板

官方模板网站：https://grafana.com/grafana/dashboards/

1. 可以在搜索框中搜索我们想要的模板

1. 找到想要的模板以后，直接复制模板代码

1. 回到我们自己的Grafana中直接import导入进去

然后就可以看到我们导入的模板了，并且可以选择不同的Exporter

### Alertmanager告警

#### 概述

- Prometheus对指标的收集、存储同告警能力分属于Prometheus Server和AlertManager两个独立的组件组成，前者仅仅负责基于告警规则生成告警通知，具体的告警操作则有后者完成；
- AlertManager负责处理由客户端发来的告警通知
  - 客户端通常是Prometheus Server，但也支持来自其他工具的告警
  - AlertManageer对告警通知进行分组、去重后根据路由规则将其路由到不同的receiver，如email、企业微信、钉钉等
- 告警逻辑
  - 在AlertManager上定义receiver，他们能够基于某个媒介接收告警信息的特定用户；
  - 在Alertmanager上定义路由规则（route），以便将收到的告警通知按需分别进行处理
  - 在Prometheus上定义告警规则生成告警通知，发送给Alertmanager

#### Alertmanager机制

除了基本的告警通知能力外，Alertmanager还支持对告警进行去重分组抑制静默和路由等功能

##### 分组机制

将相似告警合并为单个告警通知的机制，在系统因大面积故障而触发告警是，分组机制能避免用户被大量的告警噪声淹没，进而导致关键信息的隐没

##### 抑制机制

系统中某个组件或服务故障而触发告警通知后，那些依赖于该组件或服务的其他组件或服务也会因此而触发告警，抑制是避免类似的级联告警的一种特性，从而让用户的经历集中于真正的故障所在

##### 静默机制

在一个特定的时间窗口内，便接收到告警通知，Alertmanager也不会真正向用户发送告警行为；通常，在系统例行维护期间，需要激活告警系统的静默特性

#### 部署Alertmanger

1. 下载二进制包

```bash
[root@server1 ~]# wget https://github.com/prometheus/alertmanager/releases/download/v0.21.0/alertmanager-0.21.0.linux-amd64.tar.gz
```

1. 解压到指定位置以及赋予权限

```bash
[root@server1 ~]# tar -zxvf alertmanager-0.21.0.linux-amd64.tar.gz -C /data/
alertmanager-0.21.0.linux-amd64/
alertmanager-0.21.0.linux-amd64/alertmanager
alertmanager-0.21.0.linux-amd64/amtool
alertmanager-0.21.0.linux-amd64/NOTICE
alertmanager-0.21.0.linux-amd64/LICENSE
alertmanager-0.21.0.linux-amd64/alertmanager.yml
[root@server1 ~]# cd /data/
[root@server1 data]# ln -sv alertmanager-0.21.0.linux-amd64 alertmanager
"alertmanager" -> "alertmanager-0.21.0.linux-amd64"
[root@server1 data]# chown -R root:root alertmanager-0.21.0.linux-amd64
```

1. 编辑Alertmanger配置文件

默认的配置文件内容：

```bash
[root@server3 alertmanager]# cat alertmanager.yml 
global:                                # 全局配置模块
  resolve_timeout: 5m                # 用于设置处理超时时间，默认是5分钟
route:                                # 路由配置模块
  group_by: ['alertname']            # 告警分组
  group_wait: 10s                    # 10s内收到的同组告警在同一条告警通知中发送出去
  group_interval: 10s                # 同组之间发送告警通知的时间间隔
  repeat_interval: 1h                # 相同告警信息发送重复告警的周期
  receiver: 'web.hook'                # 使用的接收器名称
receivers:                            # 接收器
- name: 'web.hook'                    # 接收器名称
  webhook_configs:                    # 设置webhook地址
  - url: 'http://127.0.0.1:5001/'
inhibit_rules:                        # 告警抑制功能模块
  - source_match:
      severity: 'critical'            # 当存在源标签告警触发时抑制含有目标标签的告警
    target_match:
      severity: 'warning'            
    equal: ['alertname', 'dev', 'instance']     # 保证该配置下标签内容相同才会被抑制
```

自定义Alertmanager使用qq邮箱报警的配置文件:

```bash
[root@server1 alertmanager]# vim alertmanager.yml
global:
  resolve_timeout: 5m
  smtp_from: '2898485992@qq.com'
  smtp_smarthost: 'smtp.qq.com:465'
  smtp_auth_username: '2898485992@qq.com'
  smtp_auth_password: 'cailsiuiswridcdc'
  smtp_require_tls: false
  smtp_hello: 'qq.com'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'email'
receivers:
- name: 'email'
  email_configs:
  - to: '2898485992@qq.com'
    send_resolved: true
inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']
```

1. 启动Alertmanager

```bash
[root@server1 alertmanager]# ./alertmanager &
```

1. 关联Prometheus

```bash
[root@server1 v]# vim prometheus.yml

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - 192.168.88.10:9093
          # - alertmanager:9093
.....
  - job_name: "Alertmanager"
    static_configs:
      - targets: ["192.168.88.10:9093"]
```

1. 添加告警规则并且在Prometheus配置文件中导入

```bash
[root@server1 prometheus]# mkdir -p /data/prometheus/rules/
[root@server1 prometheus]# vim prometheus.yml 
rule_files:
  - "/data/prometheus/rules/*.yml"

[root@server1 rules]# cd /data/prometheus/rules
[root@server1 rules]# vim rules.yml 
groups:
- name: up
  rules:
  - alert: node
    expr: up{job="node_exporter"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      description: "Node has been dwon for more than 1 minutes"
      summary: "Node down"

[root@server1 prometheus]# ./promtool check rules rules/rules.yml
Checking rules/rules.yml
  SUCCESS: 1 rules found
# 重启Prometheus
[root@server1 prometheus]# systemctl restart prometheus
```

1. 在web中查看Rules

#### 关闭node-exporer测试

- Interval没有满足触发条件，告警未激活状态
- pending，已满足触发条件，但未满足告警持续时间的状态，即未满足告警中for子句指定的持续时间
- firing，已满足触发条件且已经超过for子句中指定的持续时间时的状态